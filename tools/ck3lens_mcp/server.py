"""
CK3 Lens MCP Server

An MCP server providing CK3 modding tools:
- Symbol search (from ck3raven SQLite DB)
- Conflict detection
- Live mod file operations (sandboxed)
- Git operations
- Validation

Architecture:
- ALL reads come from ck3raven's SQLite database (symbols, files, AST)
- Writes only allowed to whitelisted live mods
"""
from __future__ import annotations
import sys
import os
import importlib
from pathlib import Path
from typing import Optional, Literal

from mcp.server.fastmcp import FastMCP

# Add ck3raven to path
CK3RAVEN_ROOT = Path(__file__).parent.parent.parent / "src"
if CK3RAVEN_ROOT.exists():
    sys.path.insert(0, str(CK3RAVEN_ROOT))

from ck3lens.workspace import Session, DEFAULT_LIVE_MODS
from ck3lens.db_queries import DBQueries
from ck3lens import live_mods, git_ops
from ck3lens.validate import parse_content, validate_artifact_bundle
from ck3lens.contracts import ArtifactBundle
from ck3lens.trace import ToolTrace

# =============================================================================
# Policy Health Check - Validate imports at module load time
# =============================================================================
_policy_status = {"healthy": False, "error": None, "validated_at": None}

def _check_policy_health() -> dict:
    """
    Validate that policy module is properly importable.
    
    Returns dict with status info.
    """
    import time
    from ck3lens import policy
    
    try:
        # Force reload to ensure fresh imports
        importlib.reload(policy)
        
        # Verify required functions exist
        required = ['validate_for_mode', 'validate_policy', 'load_policy']
        missing = [f for f in required if not hasattr(policy, f)]
        
        if missing:
            _policy_status["healthy"] = False
            _policy_status["error"] = f"Missing exports: {missing}"
        else:
            _policy_status["healthy"] = True
            _policy_status["error"] = None
            
        _policy_status["validated_at"] = time.time()
        
    except Exception as e:
        _policy_status["healthy"] = False
        _policy_status["error"] = str(e)
        _policy_status["validated_at"] = time.time()
    
    return _policy_status

# Run health check at startup
_check_policy_health()

# =============================================================================

# Instance ID support for multi-window isolation
_instance_id = os.environ.get("CK3LENS_INSTANCE_ID", "default")
_server_name = f"ck3lens-{_instance_id}" if _instance_id != "default" else "ck3lens"
mcp = FastMCP(_server_name)

# Session state
_session: Optional[Session] = None
_db: Optional[DBQueries] = None
_trace: Optional[ToolTrace] = None
_playset_id: Optional[int] = None


def _get_session() -> Session:
    global _session
    if _session is None:
        from ck3lens.workspace import load_config
        _session = load_config()
    return _session


def _get_db() -> DBQueries:
    global _db
    if _db is None:
        session = _get_session()
        _db = DBQueries(db_path=session.db_path)
    return _db


def _get_playset_id() -> int:
    """Get active playset ID, auto-detecting if needed."""
    global _playset_id
    if _playset_id is None:
        db = _get_db()
        # Get the first active playset from the database
        playsets = db.conn.execute(
            "SELECT playset_id FROM playsets WHERE is_active = 1 ORDER BY updated_at DESC LIMIT 1"
        ).fetchone()
        if playsets:
            _playset_id = playsets[0]
        else:
            # Fallback: get any playset
            playsets = db.conn.execute(
                "SELECT playset_id FROM playsets ORDER BY updated_at DESC LIMIT 1"
            ).fetchone()
            _playset_id = playsets[0] if playsets else 1
    return _playset_id


def _get_lens(no_lens: bool = False):
    """
    Get the active playset lens for filtering queries.
    
    The lens is like putting on glasses - you only see content from the active playset.
    
    Args:
        no_lens: If True, return None to search ALL content (take glasses off)
    
    Returns:
        PlaysetLens object or None if no_lens=True or no playset configured
    """
    if no_lens:
        return None
    
    db = _get_db()
    return db.get_active_lens()


# Cached session scope data
_session_scope: Optional[dict] = None

# Default playset file path
DEFAULT_PLAYSET_FILE = Path.home() / "Documents" / "AI Workspace" / "active_mod_paths.json"


def _load_playset_from_file(playset_file: Path = DEFAULT_PLAYSET_FILE) -> Optional[dict]:
    """
    Load playset data from active_mod_paths.json file.
    
    This is the fallback when the database has no playsets.
    The file is generated by external tools and contains the
    same information as the database playset tables.
    
    Returns dict with same structure as _get_session_scope or None if file missing.
    """
    if not playset_file.exists():
        return None
    
    try:
        import json
        data = json.loads(playset_file.read_text(encoding='utf-8'))
        
        active_mod_ids = set()
        active_roots = set()
        
        for mod in data.get("paths", []):
            if mod.get("enabled", True):
                steam_id = mod.get("steam_id")
                if steam_id:
                    active_mod_ids.add(str(steam_id))
                path = mod.get("path")
                if path:
                    active_roots.add(path)
        
        return {
            "playset_id": None,  # No DB ID when file-based
            "playset_name": data.get("playset_name", "File-Based Playset"),
            "active_mod_ids": active_mod_ids,
            "active_roots": active_roots,
            "vanilla_version_id": None,
            "vanilla_root": str(Path("C:/Program Files (x86)/Steam/steamapps/common/Crusader Kings III/game")),
            "source": "file",
            "file_path": str(playset_file),
        }
    except Exception as e:
        print(f"Warning: Failed to load playset from {playset_file}: {e}")
        return None


def _get_session_scope(force_refresh: bool = False) -> dict:
    """
    Get all session scope data from a single source of truth.
    
    Priority:
    1. Database playset (if available and has playsets)
    2. File-based playset (active_mod_paths.json)
    
    Returns dict with:
        playset_id: Active playset ID (None if file-based)
        playset_name: Human-readable name
        active_mod_ids: Set of workshop IDs for mods in playset
        active_roots: Set of filesystem root paths for mods
        vanilla_version_id: Vanilla content version ID
        vanilla_root: Path to vanilla game files
        source: "database" or "file"
    """
    global _session_scope
    
    if _session_scope is not None and not force_refresh:
        return _session_scope
    
    # Try database first
    try:
        db = _get_db()
        playset_id = _get_playset_id()
        
        # Check if playset actually exists
        playset_info = db.conn.execute(
            "SELECT name FROM playsets WHERE playset_id = ?",
            (playset_id,)
        ).fetchone()
        
        if playset_info:
            # Database has a valid playset
            playset_name = playset_info[0]
            
            # Get all mod IDs and source paths in the active playset
            mods = db.conn.execute("""
                SELECT mp.workshop_id, mp.source_path, cv.kind
                FROM playset_mods pm
                JOIN content_versions cv ON pm.content_version_id = cv.content_version_id
                JOIN mod_packages mp ON cv.mod_package_id = mp.mod_package_id
                WHERE pm.playset_id = ? AND pm.enabled = 1
                ORDER BY pm.load_order_index
            """, (playset_id,)).fetchall()
            
            active_mod_ids = set()
            active_roots = set()
            
            for workshop_id, source_path, kind in mods:
                if workshop_id:
                    active_mod_ids.add(str(workshop_id))
                if source_path:
                    active_roots.add(source_path)
            
            # Get vanilla info
            vanilla = db.conn.execute("""
                SELECT cv.content_version_id, cv.kind, mp.source_path
                FROM content_versions cv
                LEFT JOIN mod_packages mp ON cv.mod_package_id = mp.mod_package_id
                WHERE cv.kind = 'vanilla'
                ORDER BY cv.content_version_id DESC
                LIMIT 1
            """).fetchone()
            
            vanilla_version_id = str(vanilla[0]) if vanilla else None
            vanilla_root = vanilla[2] if vanilla and vanilla[2] else None
            
            _session_scope = {
                "playset_id": playset_id,
                "playset_name": playset_name,
                "active_mod_ids": active_mod_ids,
                "active_roots": active_roots,
                "vanilla_version_id": vanilla_version_id,
                "vanilla_root": vanilla_root,
                "source": "database",
            }
            return _session_scope
    except Exception as e:
        print(f"Warning: Database playset lookup failed: {e}")
    
    # Fall back to file-based playset
    file_scope = _load_playset_from_file()
    if file_scope:
        _session_scope = file_scope
        return _session_scope
    
    # No playset available
    _session_scope = {
        "playset_id": None,
        "playset_name": None,
        "active_mod_ids": set(),
        "active_roots": set(),
        "vanilla_version_id": None,
        "vanilla_root": None,
        "source": "none",
    }
    return _session_scope


def _get_trace() -> ToolTrace:
    global _trace
    if _trace is None:
        from ck3lens.workspace import DEFAULT_CK3_MOD_DIR
        session = _get_session()
        mod_root = DEFAULT_CK3_MOD_DIR
        if session.live_mods:
            mod_root = session.live_mods[0].path.parent
        _trace = ToolTrace(mod_root / "ck3lens_trace.jsonl")
    return _trace


# ============================================================================
# Session Management
# ============================================================================


@mcp.tool()
def ck3_get_instance_info() -> dict:
    """
    Get information about this MCP server instance.
    
    Use this to verify which server instance you're connected to.
    Each VS Code window should have a unique instance ID.
    
    Returns:
        Instance ID, server name, and process info
    """
    import os
    return {
        "instance_id": _instance_id,
        "server_name": _server_name,
        "pid": os.getpid(),
        "is_isolated": _instance_id != "default",
    }



@mcp.tool()
def ck3_init_session(
    db_path: Optional[str] = None,
    live_mods: Optional[list[str]] = None
) -> dict:
    """
    Initialize the CK3 Lens session.
    
    Args:
        db_path: Path to ck3raven SQLite database (optional, uses default)
        live_mods: Override list of whitelisted live mod folder names (optional)
    
    Returns:
        Session info including mod_root and live_mods list
    """
    from ck3lens.workspace import load_config, DEFAULT_DB_PATH, DEFAULT_CK3_MOD_DIR, LiveMod
    
    global _session, _db, _trace, _playset_id, _session_scope
    
    # Reset playset and scope cache
    _playset_id = None
    _session_scope = None
    
    # Use load_config to get default session with live mods
    _session = load_config()
    
    # Override DB path if provided
    if db_path:
        _session.db_path = Path(db_path)
    
    # Override live mods if specific names provided
    if live_mods:
        _session.live_mods = [
            LiveMod(mod_id=name, name=name, path=DEFAULT_CK3_MOD_DIR / name)
            for name in live_mods
            if (DEFAULT_CK3_MOD_DIR / name).exists()
        ]
    
    _db = DBQueries(db_path=_session.db_path)
    
    # Get mod root from first live mod or default
    mod_root = DEFAULT_CK3_MOD_DIR
    if _session.live_mods:
        mod_root = _session.live_mods[0].path.parent
    _trace = ToolTrace(mod_root / "ck3lens_trace.jsonl")
    
    _trace.log("ck3lens.init_session", {"db_path": db_path, "live_mods": live_mods}, {
        "mod_root": str(mod_root),
        "live_mods_count": len(_session.live_mods)
    })
    
    # Auto-detect playset
    playset_id = _get_playset_id()
    playset_info = _db.conn.execute(
        "SELECT name, is_active FROM playsets WHERE playset_id = ?",
        (playset_id,)
    ).fetchone()
    
    # Check database health
    db_status = _check_db_health(_db.conn)
    
    result = {
        "mod_root": str(mod_root),
        "live_mods": [m.name for m in _session.live_mods],
        "db_path": str(_db.db_path) if _db.db_path else None,
        "playset_id": playset_id,
        "playset_name": playset_info[0] if playset_info else None,
        "db_status": db_status,
    }
    
    # Add warning if database needs attention
    if not db_status.get("is_complete"):
        result["warning"] = f"Database incomplete: {db_status.get('rebuild_reason', 'unknown')}. Run: python builder/daemon.py start"
    
    return result


def _check_db_health(conn) -> dict:
    """Check database build status and completeness."""
    try:
        # Check build_state table
        state_row = conn.execute("""
            SELECT value FROM build_state WHERE key = 'current'
        """).fetchone()
        
        if state_row:
            import json
            state = json.loads(state_row[0])
            is_complete = state.get('phase') == 'complete'
        else:
            state = None
            is_complete = False
        
        # Get counts
        files = conn.execute("SELECT COUNT(*) FROM files WHERE deleted = 0").fetchone()[0]
        symbols = conn.execute("SELECT COUNT(*) FROM symbols").fetchone()[0]
        refs = conn.execute("SELECT COUNT(*) FROM refs").fetchone()[0]
        
        # Determine if rebuild needed
        needs_rebuild = False
        rebuild_reason = None
        
        if not state:
            needs_rebuild = True
            rebuild_reason = "No build state found - database may not be fully initialized"
        elif not is_complete:
            needs_rebuild = True
            rebuild_reason = f"Build incomplete - stopped at phase: {state.get('phase')}"
        elif symbols == 0:
            needs_rebuild = True
            rebuild_reason = "No symbols extracted"
        elif refs == 0:
            needs_rebuild = True
            rebuild_reason = "No references extracted"
        
        return {
            "is_complete": is_complete and not needs_rebuild,
            "phase": state.get('phase') if state else "unknown",
            "last_updated": state.get('updated_at') if state else None,
            "files_indexed": files,
            "symbols_extracted": symbols,
            "refs_extracted": refs,
            "needs_rebuild": needs_rebuild,
            "rebuild_reason": rebuild_reason,
        }
    except Exception as e:
        return {
            "is_complete": False,
            "error": str(e),
            "needs_rebuild": True,
            "rebuild_reason": f"Error checking database: {e}"
        }


@mcp.tool()
def ck3_get_db_status() -> dict:
    """
    Check database build status and completeness.
    
    Returns information about:
    - Current build phase (complete, in progress, or failed)
    - File, symbol, and reference counts
    - Whether a rebuild is needed and why
    
    If the database is incomplete, provides the command to run
    for a full rebuild.
    
    Returns:
        {
            "is_complete": bool,
            "phase": "complete" | "symbol_extraction" | etc,
            "files_indexed": int,
            "symbols_extracted": int,
            "refs_extracted": int,
            "needs_rebuild": bool,
            "rebuild_reason": str or null,
            "rebuild_command": str
        }
    """
    db = _get_db()
    trace = _get_trace()
    
    status = _check_db_health(db.conn)
    status["rebuild_command"] = "python builder/daemon.py start"
    
    if status.get("needs_rebuild"):
        status["message"] = f"âš ï¸ Database needs rebuild: {status.get('rebuild_reason')}"
    else:
        status["message"] = f"âœ… Database ready: {status.get('symbols_extracted', 0):,} symbols, {status.get('refs_extracted', 0):,} refs"
    
    trace.log("ck3lens.get_db_status", {}, status)
    
    return status


@mcp.tool()
def ck3_get_policy_status() -> dict:
    """
    Check if policy enforcement is working.
    
    âš ï¸ CRITICAL: If this returns healthy=False, the agent MUST stop work
    and fix the policy system before continuing.
    
    Returns:
        {
            "healthy": bool,          # True if policy validation works
            "error": str or null,     # Error message if broken
            "validated_at": float,    # Timestamp of last check
            "message": str            # Human-readable status
        }
    """
    import time
    
    trace = _get_trace()
    
    # Run fresh health check
    health = _check_policy_health()
    
    result = {
        "healthy": health["healthy"],
        "error": health["error"],
        "validated_at": health["validated_at"],
    }
    
    if health["healthy"]:
        result["message"] = "âœ… Policy enforcement is ACTIVE"
    else:
        result["message"] = f"ðŸš¨ POLICY ENFORCEMENT IS DOWN: {health['error']}"
        result["action_required"] = "Agent must stop work. Fix policy module or restart MCP server."
    
    trace.log("ck3lens.get_policy_status", {}, result)
    
    return result


# ============================================================================
# Unified Search Tool
# ============================================================================

@mcp.tool()
def ck3_search(
    query: str,
    file_pattern: Optional[str] = None,
    source_filter: Optional[str] = None,
    symbol_type: Optional[str] = None,
    adjacency: Literal["auto", "strict", "fuzzy"] = "auto",
    limit: int = 50,
    definitions_only: bool = False,
    verbose: bool = False,
    no_lens: bool = False
) -> dict:
    """
    Unified search across symbols, file content, and file paths.
    
    This is THE search tool - it searches EVERYTHING:
    1. Symbol definitions (traits, events, decisions, etc.)
    2. Symbol USAGES (where symbols are referenced - DEFAULT behavior)
    3. File content (grep-style text matches with line numbers)
    4. File paths (if query looks like a path or file_pattern provided)
    
    By default, shows BOTH definitions AND usages - critical for compatch work
    where you need to understand how something is used, not just where it's defined.
    
    Args:
        query: Search term (symbol name, text to find, or file path)
        file_pattern: SQL LIKE pattern to filter file paths (e.g., "%traits%")
        source_filter: Filter by source ("vanilla" or mod name)
        symbol_type: Filter symbols by type (trait, event, decision, etc.)
        adjacency: Pattern expansion ("auto", "strict", "fuzzy")
        limit: Max results per category
        definitions_only: If True, skip references (faster but less useful)
        verbose: More detail (all matches per file, snippets)
        no_lens: If True, search ALL content (not just active playset)
    
    Returns:
        {
            "query": str,
            "symbols": {
                "count": int,           # Definition count
                "results": [...],       # Definitions with file/line
                "definitions_by_mod": {...},
                "references_by_mod": {...}  # WHERE it's used (DEFAULT!)
            },
            "content": {count, results (line-by-line matches)},
            "files": {count, results (matching file paths)}
        }
    
    AGENT RULE: A null/empty answer is ONLY valid if BOTH symbols AND content
    searches return empty. Filename-only searches are NOT sufficient to claim
    something doesn't exist.
    """
    db = _get_db()
    trace = _get_trace()
    lens = _get_lens(no_lens=no_lens)
    
    # By default, include references (usages) - this is what compatch needs
    include_references = not definitions_only
    
    result = db.unified_search(
        lens=lens,
        query=query,
        file_pattern=file_pattern,
        source_filter=source_filter,
        symbol_type=symbol_type,
        adjacency=adjacency,
        limit=limit,
        matches_per_file=5,
        include_references=include_references,
        verbose=verbose
    )
    
    trace.log("ck3lens.search", {
        "query": query,
        "file_pattern": file_pattern,
        "symbol_type": symbol_type,
        "adjacency": adjacency,
        "definitions_only": definitions_only,
        "no_lens": no_lens
    }, {
        "symbols_count": result["symbols"]["count"],
        "references_count": len(result["symbols"].get("references_by_mod", {})),
        "content_count": result["content"]["count"],
        "files_count": result["files"]["count"]
    })
    
    return result


# ============================================================================
# Symbol Search Tools (from ck3raven DB) - LEGACY, use ck3_search instead
# ============================================================================

@mcp.tool()
def ck3_search_symbols(
    query: str,
    symbol_type: Optional[str] = None,
    mod_filter: Optional[list[str]] = None,
    adjacency: Literal["auto", "strict", "fuzzy"] = "auto",
    limit: int = 50,
    include_references: bool = False,
    verbose: bool = False,
    no_lens: bool = False
) -> dict:
    """
    Search symbols in the ck3raven database with adjacency pattern expansion.
    
    IMPORTANT: This uses adjacency search which automatically expands queries:
    - "combat_skill" also matches "combat_*_skill", "*_combat_skill", etc.
    - Use adjacency="strict" to disable expansion (exact matches only)
    - Use adjacency="fuzzy" for maximum flexibility
    
    Args:
        query: Search query (symbol name, partial name, or pattern)
        symbol_type: Filter by type (trait, decision, event, etc.)
        mod_filter: Only search in these mods (list of mod_id strings)
        adjacency: Pattern expansion mode ("auto", "strict", "fuzzy")
        limit: Maximum results to return
        include_references: If True, also return which mods reference the symbol
        verbose: If True, include code snippets for definitions
        no_lens: If True, search ALL content (not just active playset)
    
    Returns:
        {
            results: [...],  # Exact matches with file/line
            adjacencies: [...],  # Similar names
            definitions_by_mod: {...},  # Grouped by mod for easy reading
            references_by_mod: {...}  # If include_references=True
        }
    """
    db = _get_db()
    trace = _get_trace()
    lens = _get_lens(no_lens=no_lens)
    
    results = db.search_symbols(
        lens=lens,
        query=query,
        symbol_type=symbol_type,
        adjacency=adjacency,
        limit=limit,
        include_references=include_references,
        verbose=verbose
    )
    
    trace.log("ck3lens.search_symbols", {
        "query": query,
        "symbol_type": symbol_type,
        "adjacency": adjacency,
        "include_references": include_references,
        "no_lens": no_lens
    }, {
        "results_count": len(results.get("results", [])),
        "adjacencies_count": len(results.get("adjacencies", []))
    })
    
    # Add lens info to response
    results["query"] = query
    results["adjacency_mode"] = adjacency
    results["lens"] = lens.playset_name if lens else "ALL CONTENT (no lens)"
    
    return results


@mcp.tool()
def ck3_confirm_not_exists(
    name: str,
    symbol_type: Optional[str] = None,
    no_lens: bool = False
) -> dict:
    """
    Confirm a symbol does NOT exist before claiming it's missing.
    
    This performs an exhaustive fuzzy search to prevent false negatives.
    ALWAYS call this before writing code that assumes something doesn't exist.
    
    Args:
        name: Symbol name to search for
        symbol_type: Optional type filter (trait, decision, etc.)
        no_lens: If True, search ALL content (not just active playset)
    
    Returns:
        - can_claim_not_exists: True if exhaustive search found nothing
        - similar_matches: Any similar symbols found (might be what you meant)
    """
    db = _get_db()
    trace = _get_trace()
    lens = _get_lens(no_lens=no_lens)
    
    result = db.confirm_not_exists(lens, name, symbol_type)
    
    trace.log("ck3lens.confirm_not_exists", {
        "name": name,
        "symbol_type": symbol_type
    }, {
        "can_claim": result["can_claim_not_exists"],
        "adjacencies_count": len(result.get("adjacencies", []))
    })
    
    return result


@mcp.tool()
def ck3_get_file(
    file_path: str,
    include_ast: bool = False,
    max_bytes: int = 200000,
    no_lens: bool = False
) -> dict:
    """
    Get file content from the ck3raven database.
    
    Args:
        file_path: Relative path to the file (e.g., "common/traits/00_traits.txt")
        include_ast: If True, also return parsed AST representation
        max_bytes: Maximum content bytes to return
        no_lens: If True, search ALL content (not just active playset)
    
    Returns:
        File content (raw and/or AST)
    """
    db = _get_db()
    trace = _get_trace()
    lens = _get_lens(no_lens=no_lens)
    
    result = db.get_file(lens, relpath=file_path, include_ast=include_ast)
    
    trace.log("ck3lens.get_file", {
        "file_path": file_path,
        "include_ast": include_ast
    }, {
        "found": result is not None,
        "content_length": len(result.get("content", "")) if result else 0
    })
    
    if result:
        result["lens"] = lens.playset_name if lens else "ALL CONTENT (no lens)"
    
    return result or {"error": f"File not found: {file_path}"}


@mcp.tool()
def ck3_get_conflicts(
    path_pattern: Optional[str] = None,
    symbol_name: Optional[str] = None,
    symbol_type: Optional[str] = None
) -> dict:
    """
    Get load-order conflicts from the SQLResolver.
    
    Args:
        path_pattern: Filter by file path pattern (glob-style)
        symbol_name: Filter by specific symbol name
        symbol_type: Filter by symbol type
    
    Returns:
        List of conflicts with winner/loser mods and resolution type
    """
    db = _get_db()
    trace = _get_trace()
    lens = _get_lens()
    
    if not lens:
        return {"error": "No active playset. Use ck3_set_active_playset first."}
    
    conflicts = db.get_conflicts(
        lens=lens,
        folder=path_pattern,
        symbol_type=symbol_type
    )
    
    trace.log("ck3lens.get_conflicts", {
        "path_pattern": path_pattern,
        "symbol_name": symbol_name,
        "symbol_type": symbol_type
    }, {"conflicts_count": len(conflicts)})
    
    return {"conflicts": conflicts}


# ============================================================================
# Live Mod Operations (sandboxed writes)
# ============================================================================

@mcp.tool()
def ck3_list_live_mods() -> dict:
    """
    List whitelisted live mods that can be modified.
    
    Returns:
        List of mod names and paths that are available for writing
    """
    session = _get_session()
    trace = _get_trace()
    
    mods = live_mods.list_live_mods(session)
    
    trace.log("ck3lens.list_live_mods", {}, {"mods_count": len(mods)})
    
    return {"live_mods": mods}


@mcp.tool()
def ck3_read_live_file(
    mod_name: str,
    rel_path: str,
    max_bytes: int = 200000
) -> dict:
    """
    Read a file from a whitelisted live mod.
    
    Args:
        mod_name: Name of the live mod (folder name)
        rel_path: Relative path within the mod
        max_bytes: Maximum bytes to read
    
    Returns:
        File content
    """
    session = _get_session()
    trace = _get_trace()
    
    result = live_mods.read_live_file(session, mod_name, rel_path, max_bytes)
    
    trace.log("ck3lens.read_live_file", {
        "mod_name": mod_name,
        "rel_path": rel_path
    }, {"success": result.get("success", False)})
    
    return result


@mcp.tool()
def ck3_write_file(
    mod_name: str,
    rel_path: str,
    content: str,
    validate_syntax: bool = True
) -> dict:
    """
    Write a file to a whitelisted live mod.
    
    Args:
        mod_name: Name of the live mod (must be whitelisted)
        rel_path: Relative path within the mod
        content: File content to write
        validate_syntax: If True, validate CK3 script syntax before writing
    
    Returns:
        Success status and validation results
    """
    session = _get_session()
    trace = _get_trace()
    
    # Optional syntax validation
    if validate_syntax and rel_path.endswith(".txt"):
        parse_result = parse_content(content, rel_path)
        if not parse_result["success"]:
            trace.log("ck3lens.write_file", {
                "mod_name": mod_name,
                "rel_path": rel_path
            }, {"success": False, "reason": "syntax_error"})
            return {
                "success": False,
                "error": "Syntax validation failed",
                "parse_errors": parse_result["errors"]
            }
    
    result = live_mods.write_file(session, mod_name, rel_path, content)
    
    trace.log("ck3lens.write_file", {
        "mod_name": mod_name,
        "rel_path": rel_path,
        "content_length": len(content)
    }, {"success": result.get("success", False)})
    
    return result


@mcp.tool()
def ck3_edit_file(
    mod_name: str,
    rel_path: str,
    old_content: str,
    new_content: str,
    validate_syntax: bool = True
) -> dict:
    """
    Edit a file in a whitelisted live mod (search-replace style).
    
    Args:
        mod_name: Name of the live mod
        rel_path: Relative path within the mod
        old_content: Exact content to find and replace
        new_content: Content to replace with
        validate_syntax: If True, validate resulting syntax
    
    Returns:
        Success status
    """
    session = _get_session()
    trace = _get_trace()
    
    result = live_mods.edit_file(session, mod_name, rel_path, old_content, new_content)
    
    # Validate resulting file if requested
    if result.get("success") and validate_syntax and rel_path.endswith(".txt"):
        read_result = live_mods.read_live_file(session, mod_name, rel_path)
        if read_result.get("success"):
            parse_result = parse_content(read_result["content"], rel_path)
            result["syntax_valid"] = parse_result["success"]
            if not parse_result["success"]:
                result["syntax_warnings"] = parse_result["errors"]
    
    trace.log("ck3lens.edit_file", {
        "mod_name": mod_name,
        "rel_path": rel_path
    }, {"success": result.get("success", False)})
    
    return result


@mcp.tool()
def ck3_delete_file(
    mod_name: str,
    rel_path: str
) -> dict:
    """
    Delete a file from a whitelisted live mod.
    
    Args:
        mod_name: Name of the live mod
        rel_path: Relative path within the mod
    
    Returns:
        Success status
    """
    session = _get_session()
    trace = _get_trace()
    
    result = live_mods.delete_file(session, mod_name, rel_path)
    
    trace.log("ck3lens.delete_file", {
        "mod_name": mod_name,
        "rel_path": rel_path
    }, {"success": result.get("success", False)})
    
    return result


@mcp.tool()
def ck3_rename_file(
    mod_name: str,
    old_rel_path: str,
    new_rel_path: str
) -> dict:
    """
    Rename or move a file within a whitelisted live mod.
    
    Args:
        mod_name: Name of the live mod
        old_rel_path: Current relative path within the mod
        new_rel_path: New relative path within the mod
    
    Returns:
        Success status
    """
    session = _get_session()
    trace = _get_trace()
    
    result = live_mods.rename_file(session, mod_name, old_rel_path, new_rel_path)
    
    trace.log("ck3lens.rename_file", {
        "mod_name": mod_name,
        "old_rel_path": old_rel_path,
        "new_rel_path": new_rel_path
    }, {"success": result.get("success", False)})
    
    return result


@mcp.tool()
def ck3_create_override_patch(
    source_path: str,
    target_mod: str,
    mode: Literal["override_patch", "full_replace"],
    initial_content: str | None = None,
) -> dict:
    """
    Create an override patch file in a live mod.
    
    Use this when you need to patch a file from vanilla or a non-editable mod.
    Automatically creates the correct directory structure and follows naming conventions.
    
    Modes:
    - override_patch: Creates zzz_msc_[original_name].txt (for adding/modifying specific units)
    - full_replace: Creates [original_name].txt (full replacement, last-wins)
    
    Args:
        source_path: The relative path being overridden (e.g., "common/traits/00_traits.txt")
        target_mod: Name of the live mod to create the patch in (e.g., "MSC")
        mode: "override_patch" for partial override, "full_replace" for full replacement
        initial_content: Optional initial content for the file. If None, creates with comment header.
    
    Returns:
        {
            "success": bool,
            "created_path": str,  # Relative path in target mod
            "full_path": str,     # Absolute filesystem path
            "mode": str,
            "source_path": str
        }
    
    Example:
        ck3_create_override_patch(
            source_path="common/traits/00_traits.txt",
            target_mod="MSC",
            mode="override_patch"
        )
        # Creates: MSC/common/traits/zzz_msc_00_traits.txt
    """
    from pathlib import Path as P
    from datetime import datetime
    
    session = _get_session()
    trace = _get_trace()
    
    # Parse source path
    source = P(source_path)
    if source.is_absolute() or ".." in source.parts:
        return {"success": False, "error": "source_path must be relative without .."}
    
    # Determine output filename
    if mode == "override_patch":
        # zzz_msc_[original_name].txt
        new_name = f"zzz_msc_{source.name}"
    elif mode == "full_replace":
        # Same name (will override due to load order)
        new_name = source.name
    else:
        return {"success": False, "error": f"Invalid mode: {mode}. Use 'override_patch' or 'full_replace'"}
    
    # Build target path (same directory structure)
    target_rel_path = str(source.parent / new_name)
    
    # Generate default content if not provided
    if initial_content is None:
        initial_content = f"""# Override patch for: {source_path}
# Created: {datetime.now().strftime("%Y-%m-%d %H:%M")}
# Mode: {mode}
# 
# Add your overrides below. For 'override_patch' mode, only include
# the specific units you want to override/add.

"""
    
    # Write the file
    result = live_mods.write_file(session, target_mod, target_rel_path, initial_content)
    
    if result.get("success"):
        # Get the full path for navigation
        live_mod = session.get_live_mod(target_mod)
        full_path = str(live_mod.path / target_rel_path) if live_mod else None
        
        trace.log("ck3lens.create_override_patch", {
            "source_path": source_path,
            "target_mod": target_mod,
            "mode": mode
        }, {"success": True, "created_path": target_rel_path})
        
        return {
            "success": True,
            "created_path": target_rel_path,
            "full_path": full_path,
            "mode": mode,
            "source_path": source_path,
            "message": f"Created override patch: {target_rel_path}"
        }
    else:
        trace.log("ck3lens.create_override_patch", {
            "source_path": source_path,
            "target_mod": target_mod,
            "mode": mode
        }, {"success": False, "error": result.get("error")})
        
        return result


@mcp.tool()
def ck3_list_live_files(
    mod_name: str,
    path_prefix: Optional[str] = None,
    pattern: Optional[str] = None
) -> dict:
    """
    List files in a whitelisted live mod.
    
    Args:
        mod_name: Name of the live mod
        path_prefix: Filter by path prefix (e.g., "common/traits")
        pattern: Glob pattern filter (e.g., "*.txt")
    
    Returns:
        List of file paths
    """
    session = _get_session()
    trace = _get_trace()
    
    result = live_mods.list_live_files(session, mod_name, path_prefix, pattern)
    
    trace.log("ck3lens.list_live_files", {
        "mod_name": mod_name,
        "path_prefix": path_prefix,
        "pattern": pattern
    }, {"files_count": len(result.get("files", []))})
    
    return result


# ============================================================================
# Filesystem Wrapper Tools (Traceable)
# ============================================================================
# These tools wrap VS Code's built-in filesystem operations to make them
# traceable by the policy validator. Agents should use these instead of
# read_file, list_dir, grep_search directly when working in ck3lens mode.

@mcp.tool()
def ck3_read_raw_file(
    path: str,
    justification: str,
    start_line: int = 1,
    end_line: Optional[int] = None
) -> dict:
    """
    Read a file from the filesystem with tracing and justification.
    
    USE THIS instead of VS Code's read_file when you need to read files
    outside the ck3raven database. Every read is logged for policy validation.
    
    Args:
        path: Absolute path to the file to read
        justification: Why this file needs to be read (for audit trail)
        start_line: Line to start reading from (1-indexed)
        end_line: Line to stop reading at (inclusive, None = EOF)
    
    Returns:
        {"success": bool, "content": str, "lines_read": int, "total_lines": int}
    """
    trace = _get_trace()
    file_path = Path(path)
    
    # Log the attempt
    trace.log("ck3lens.read_raw_file", {
        "path": str(file_path),
        "justification": justification,
        "start_line": start_line,
        "end_line": end_line,
    }, {})
    
    if not file_path.exists():
        return {"success": False, "error": f"File not found: {path}"}
    
    if not file_path.is_file():
        return {"success": False, "error": f"Not a file: {path}"}
    
    try:
        # Read all lines
        with open(file_path, 'r', encoding='utf-8', errors='replace') as f:
            all_lines = f.readlines()
        
        total_lines = len(all_lines)
        
        # Apply line range
        start_idx = max(0, start_line - 1)
        end_idx = end_line if end_line else total_lines
        end_idx = min(end_idx, total_lines)
        
        selected_lines = all_lines[start_idx:end_idx]
        content = ''.join(selected_lines)
        
        result = {
            "success": True,
            "content": content,
            "lines_read": len(selected_lines),
            "total_lines": total_lines,
            "path": str(file_path),
        }
        
        trace.log("ck3lens.read_raw_file.result", {
            "path": str(file_path),
        }, {"lines_read": len(selected_lines), "total_lines": total_lines})
        
        return result
        
    except Exception as e:
        return {"success": False, "error": str(e)}


@mcp.tool()
def ck3_list_raw_dir(
    path: str,
    justification: str,
    pattern: Optional[str] = None,
    recursive: bool = False
) -> dict:
    """
    List directory contents from the filesystem with tracing.
    
    USE THIS instead of VS Code's list_dir when you need to browse files
    outside the ck3raven database. Every listing is logged for policy validation.
    
    Args:
        path: Absolute path to the directory
        justification: Why this directory needs to be listed (for audit trail)
        pattern: Optional glob pattern to filter files (e.g., "*.txt")
        recursive: If True, list recursively
    
    Returns:
        {"success": bool, "entries": [{"name": str, "is_dir": bool, "path": str}]}
    """
    trace = _get_trace()
    dir_path = Path(path)
    
    # Log the attempt
    trace.log("ck3lens.list_raw_dir", {
        "path": str(dir_path),
        "justification": justification,
        "pattern": pattern,
        "recursive": recursive,
    }, {})
    
    if not dir_path.exists():
        return {"success": False, "error": f"Directory not found: {path}"}
    
    if not dir_path.is_dir():
        return {"success": False, "error": f"Not a directory: {path}"}
    
    try:
        entries = []
        
        if recursive:
            # Recursive listing with optional pattern
            if pattern:
                for p in dir_path.rglob(pattern):
                    entries.append({
                        "name": p.name,
                        "is_dir": p.is_dir(),
                        "path": str(p),
                        "relpath": str(p.relative_to(dir_path)),
                    })
            else:
                for p in dir_path.rglob("*"):
                    entries.append({
                        "name": p.name,
                        "is_dir": p.is_dir(),
                        "path": str(p),
                        "relpath": str(p.relative_to(dir_path)),
                    })
        else:
            # Non-recursive listing
            for p in dir_path.iterdir():
                if pattern:
                    import fnmatch
                    if not fnmatch.fnmatch(p.name, pattern):
                        continue
                entries.append({
                    "name": p.name,
                    "is_dir": p.is_dir(),
                    "path": str(p),
                })
        
        result = {
            "success": True,
            "entries": entries,
            "count": len(entries),
            "path": str(dir_path),
        }
        
        trace.log("ck3lens.list_raw_dir.result", {
            "path": str(dir_path),
        }, {"count": len(entries)})
        
        return result
        
    except Exception as e:
        return {"success": False, "error": str(e)}


@mcp.tool()
def ck3_grep_raw(
    path: str,
    query: str,
    justification: str,
    is_regex: bool = False,
    include_pattern: Optional[str] = None
) -> dict:
    """
    Search for text in files with tracing.
    
    USE THIS instead of VS Code's grep_search when you need to search files
    outside the ck3raven database. Every search is logged for policy validation.
    
    Args:
        path: Absolute path to search in (file or directory)
        query: Text or regex pattern to search for
        justification: Why this search is needed (for audit trail)
        is_regex: If True, treat query as regex
        include_pattern: Glob pattern to filter files (e.g., "*.txt")
    
    Returns:
        {"success": bool, "matches": [{"file": str, "line": int, "content": str}]}
    """
    import re
    trace = _get_trace()
    search_path = Path(path)
    
    # Log the attempt
    trace.log("ck3lens.grep_raw", {
        "path": str(search_path),
        "query": query,
        "justification": justification,
        "is_regex": is_regex,
        "include_pattern": include_pattern,
    }, {})
    
    if not search_path.exists():
        return {"success": False, "error": f"Path not found: {path}"}
    
    try:
        matches = []
        
        # Compile pattern
        if is_regex:
            pattern = re.compile(query, re.IGNORECASE)
        else:
            pattern = re.compile(re.escape(query), re.IGNORECASE)
        
        # Get files to search
        if search_path.is_file():
            files = [search_path]
        else:
            if include_pattern:
                files = list(search_path.rglob(include_pattern))
            else:
                files = list(search_path.rglob("*.txt"))
        
        # Search each file
        for file_path in files[:100]:  # Limit to 100 files
            if not file_path.is_file():
                continue
            try:
                with open(file_path, 'r', encoding='utf-8', errors='replace') as f:
                    for line_num, line in enumerate(f, 1):
                        if pattern.search(line):
                            matches.append({
                                "file": str(file_path),
                                "line": line_num,
                                "content": line.rstrip()[:200],  # Truncate long lines
                            })
                            if len(matches) >= 50:  # Limit matches
                                break
            except Exception:
                continue
            
            if len(matches) >= 50:
                break
        
        result = {
            "success": True,
            "matches": matches,
            "count": len(matches),
            "truncated": len(matches) >= 50,
        }
        
        trace.log("ck3lens.grep_raw.result", {
            "path": str(search_path),
            "query": query,
        }, {"match_count": len(matches)})
        
        return result
        
    except Exception as e:
        return {"success": False, "error": str(e)}


@mcp.tool()
def ck3_file_search(
    pattern: str,
    justification: str,
    base_path: Optional[str] = None
) -> dict:
    """
    Search for files by glob pattern with tracing.
    
    USE THIS instead of VS Code's file_search when you need to find files
    outside the ck3raven database. Every search is logged for policy validation.
    
    Args:
        pattern: Glob pattern to match (e.g., "**/*.txt", "common/traits/*.txt")
        justification: Why this search is needed (for audit trail)
        base_path: Base directory to search in (defaults to vanilla game path)
    
    Returns:
        {"success": bool, "files": [str], "count": int}
    """
    trace = _get_trace()
    scope = _get_session_scope()
    
    # Default to vanilla path if available
    if base_path:
        search_base = Path(base_path)
    elif scope.get("vanilla_root"):
        search_base = Path(scope["vanilla_root"])
    else:
        search_base = Path("C:/Program Files (x86)/Steam/steamapps/common/Crusader Kings III/game")
    
    # Log the attempt
    trace.log("ck3lens.file_search", {
        "pattern": pattern,
        "base_path": str(search_base),
        "justification": justification,
    }, {})
    
    if not search_base.exists():
        return {"success": False, "error": f"Base path not found: {search_base}"}
    
    try:
        files = []
        for p in search_base.glob(pattern):
            if p.is_file():
                files.append(str(p))
                if len(files) >= 500:  # Limit results
                    break
        
        result = {
            "success": True,
            "files": files,
            "count": len(files),
            "truncated": len(files) >= 500,
            "base_path": str(search_base),
        }
        
        trace.log("ck3lens.file_search.result", {
            "pattern": pattern,
        }, {"count": len(files)})
        
        return result
        
    except Exception as e:
        return {"success": False, "error": str(e)}


@mcp.tool()
def ck3_get_scope_info() -> dict:
    """
    Get current session scope information.
    
    Returns the active lens (playset) used for all scoped operations.
    The lens is like wearing glasses - it filters what you see in the database.
    
    Returns:
        {
            "lens_active": bool,
            "playset_id": int or None,
            "playset_name": str,
            "mod_count": int,
            "mods": [{name, workshop_id}]
        }
    """
    db = _get_db()
    lens = _get_lens(no_lens=False)
    
    if not lens:
        return {
            "lens_active": False,
            "playset_id": None,
            "playset_name": None,
            "mod_count": 0,
            "mods": [],
            "hint": "No active playset. Use ck3_switch_playset to activate one."
        }
    
    # Get mod details for this lens
    if lens.mod_cv_ids:
        placeholders = ",".join("?" * len(lens.mod_cv_ids))
        mods = db.conn.execute(f"""
            SELECT cv.name, cv.workshop_id, pm.load_order
            FROM content_versions cv
            JOIN playset_mods pm ON cv.content_version_id = pm.content_version_id
            WHERE cv.content_version_id IN ({placeholders})
            ORDER BY pm.load_order
        """, lens.mod_cv_ids).fetchall()
    else:
        mods = []
    
    return {
        "lens_active": True,
        "playset_id": lens.playset_id,
        "playset_name": lens.playset_name,
        "mod_count": len(lens.mod_cv_ids),
        "mods": [{"name": m[0], "workshop_id": m[1], "load_order": m[2]} for m in mods]
    }


# ============================================================================
# Validation Tools
# ============================================================================

@mcp.tool()
def ck3_parse_content(
    content: str,
    filename: str = "inline.txt"
) -> dict:
    """
    Parse CK3 script content and return AST or errors.
    
    Uses error-recovering parser that collects ALL errors instead of
    stopping at the first one. Returns partial AST even when errors occur.
    
    Args:
        content: CK3 script content to parse
        filename: Optional filename for error messages
    
    Returns:
        {
            "success": bool (true if no errors),
            "ast": {...} (partial AST, may be valid despite errors),
            "errors": [
                {
                    "line": 5,
                    "column": 10,
                    "end_line": 5,
                    "end_column": 15,
                    "message": "Expected value after operator",
                    "code": "PARSE_ERROR",
                    "severity": "error"
                },
                ...
            ]
        }
    """
    trace = _get_trace()
    
    result = parse_content(content, filename, recover=True)
    
    trace.log("ck3lens.parse_content", {
        "filename": filename,
        "content_length": len(content)
    }, {"success": result["success"], "error_count": len(result["errors"])})
    
    return result


@mcp.tool()
def ck3_validate_artifact_bundle(artifact_bundle: dict) -> dict:
    """
    Validate an ArtifactBundle contract.
    
    Checks path policy, parses content, and validates references.
    
    Args:
        artifact_bundle: ArtifactBundle as dict (artifacts list with path/content/format)
    
    Returns:
        ValidationReport with errors and warnings
    """
    trace = _get_trace()
    
    bundle = ArtifactBundle.model_validate(artifact_bundle)
    report = validate_artifact_bundle(bundle)
    
    trace.log("ck3lens.validate_artifact_bundle", {
        "artifact_count": len(bundle.artifacts)
    }, {"ok": report.ok, "errors": len(report.errors)})
    
    return report.model_dump()


@mcp.tool()
def ck3_validate_policy(
    mode: Literal["ck3lens", "ck3raven-dev"],
    artifact_bundle: dict | None = None,
    session_start_ts: float | None = None,
) -> dict:
    """
    Validate agent behavior against the policy specification.
    
    This is the delivery gate for agent outputs. It checks:
    - Global rules (trace required, no silent assumptions)
    - Mode-specific rules (ck3lens or ck3raven-dev)
    - ArtifactBundle validation (if provided)
    
    Call this before claiming a task is complete to verify policy compliance.
    
    Args:
        mode: Agent mode - "ck3lens" for modding, "ck3raven-dev" for infrastructure
        artifact_bundle: Optional ArtifactBundle dict being delivered
        session_start_ts: Optional timestamp to limit trace scope
    
    Returns:
        PolicyOutcome with deliverable status, violations, and summary
    """
    import time
    
    trace = _get_trace()
    
    # Check policy health first - fail fast if broken
    health = _check_policy_health()
    if not health["healthy"]:
        error_result = {
            "status": "error",
            "deliverable": False,
            "policy_healthy": False,
            "error": f"Policy module broken: {health['error']}",
            "message": "âš ï¸ POLICY ENFORCEMENT IS DOWN. Agent must stop work until fixed.",
            "violations": [{
                "severity": "error",
                "rule_id": "POLICY_IMPORT_FAILED",
                "message": f"Cannot import policy module: {health['error']}",
            }],
            "rules_checked": [],
        }
        trace.log("ck3lens.validate_policy", {
            "mode": mode,
            "policy_error": health["error"],
        }, {"deliverable": False, "error": "policy_broken"})
        return error_result
    
    # Import with fresh reload
    from ck3lens import policy
    importlib.reload(policy)
    
    # Get trace events
    if session_start_ts:
        trace_events = trace.get_session_trace(session_start_ts)
    else:
        # Get last 100 events
        trace_events = trace.read_recent(max_events=100)
    
    # Get playset context
    playset_id = _get_playset_id()
    
    # Run validation
    result = policy.validate_for_mode(
        mode=mode,
        trace=trace_events,
        artifact_bundle_dict=artifact_bundle,
        playset_id=playset_id,
    )
    
    # Add health status to result
    result["policy_healthy"] = True
    
    trace.log("ck3lens.validate_policy", {
        "mode": mode,
        "has_artifact_bundle": artifact_bundle is not None,
        "trace_events": len(trace_events),
    }, {
        "deliverable": result.get("deliverable", False),
        "error_count": result.get("summary", {}).get("violations_error_count", 0),
    })
    
    return result


@mcp.tool()
def ck3_report_validation_issue(
    issue_type: Literal["parser_false_positive", "reference_false_positive", "parser_missed_error", "other"],
    code_snippet: str,
    expected_behavior: str,
    actual_behavior: str,
    notes: str | None = None,
) -> dict:
    """
    Report a validation false positive or missed error.
    
    Use this when the parser or reference validator produces incorrect results.
    These reports help improve ck3raven's validation accuracy.
    
    Issue types:
    - parser_false_positive: Parser rejected valid CK3 syntax
    - reference_false_positive: Reference checker flagged a valid symbol
    - parser_missed_error: Parser accepted invalid CK3 syntax
    - other: Other validation issues
    
    Args:
        issue_type: Category of validation issue
        code_snippet: The CK3 code that was incorrectly validated
        expected_behavior: What should have happened
        actual_behavior: What actually happened
        notes: Optional additional context
    
    Returns:
        Confirmation with issue ID for tracking
    """
    import json
    import hashlib
    from datetime import datetime
    
    trace = _get_trace()
    session = _get_session()
    
    # Create issue record
    issue_id = hashlib.sha256(
        f"{issue_type}:{code_snippet[:100]}:{datetime.now().isoformat()}".encode()
    ).hexdigest()[:12]
    
    issue = {
        "issue_id": issue_id,
        "issue_type": issue_type,
        "code_snippet": code_snippet,
        "expected_behavior": expected_behavior,
        "actual_behavior": actual_behavior,
        "notes": notes,
        "reported_at": datetime.now().isoformat(),
        "status": "open",
    }
    
    # Write to issues file in mod root
    issues_file = session.mod_root / "ck3lens_validation_issues.jsonl"
    with issues_file.open("a", encoding="utf-8") as f:
        f.write(json.dumps(issue, ensure_ascii=False) + "\n")
    
    trace.log("ck3lens.report_validation_issue", {
        "issue_type": issue_type,
        "snippet_length": len(code_snippet)
    }, {"issue_id": issue_id})
    
    return {
        "success": True,
        "issue_id": issue_id,
        "message": f"Validation issue recorded. ID: {issue_id}. Will be reviewed in ck3raven-dev mode.",
        "issues_file": str(issues_file)
    }


@mcp.tool()
def ck3_validate_python(
    file_path: str | None = None,
    code_snippet: str | None = None,
) -> dict:
    """
    Validate Python code for syntax and import errors.
    
    Use this before deploying any Python code changes to ensure they are valid.
    This is MANDATORY for ck3raven-dev mode work.
    
    Provide either:
    - file_path: Path to a Python file to validate
    - code_snippet: Python code string to validate
    
    Args:
        file_path: Absolute path to Python file to check
        code_snippet: Python code string to validate (if no file_path)
    
    Returns:
        {
            "valid": bool,
            "errors": [...],
            "warnings": [...]
        }
    """
    import ast
    import subprocess
    import tempfile
    
    trace = _get_trace()
    errors: list[dict] = []
    warnings: list[dict] = []
    
    code_to_check = None
    source_desc = "snippet"
    
    if file_path:
        from pathlib import Path
        p = Path(file_path)
        if not p.exists():
            return {"valid": False, "errors": [{"message": f"File not found: {file_path}"}], "warnings": []}
        code_to_check = p.read_text(encoding="utf-8")
        source_desc = str(p)
    elif code_snippet:
        code_to_check = code_snippet
    else:
        return {"valid": False, "errors": [{"message": "Provide either file_path or code_snippet"}], "warnings": []}
    
    # Step 1: Python AST syntax check
    try:
        ast.parse(code_to_check)
    except SyntaxError as e:
        errors.append({
            "type": "syntax",
            "line": e.lineno,
            "column": e.offset,
            "message": str(e.msg),
            "source": source_desc
        })
        # Syntax error is fatal - return immediately
        trace.log("ck3lens.validate_python", {"source": source_desc}, {"valid": False, "error_count": 1})
        return {"valid": False, "errors": errors, "warnings": []}
    
    # Step 2: Try to compile (catches more issues)
    try:
        compile(code_to_check, source_desc, 'exec')
    except Exception as e:
        errors.append({
            "type": "compile",
            "message": str(e),
            "source": source_desc
        })
    
    # Step 3: For file paths, try running Python -m py_compile
    if file_path and not errors:
        try:
            result = subprocess.run(
                ["python", "-m", "py_compile", file_path],
                capture_output=True,
                text=True,
                timeout=10
            )
            if result.returncode != 0:
                errors.append({
                    "type": "py_compile",
                    "message": result.stderr.strip(),
                    "source": source_desc
                })
        except subprocess.TimeoutExpired:
            warnings.append({"type": "timeout", "message": "py_compile check timed out"})
        except Exception as e:
            warnings.append({"type": "subprocess", "message": f"Could not run py_compile: {e}"})
    
    # Step 4: Basic import checking for common issues
    import_lines = [line for line in code_to_check.split('\n') if line.strip().startswith(('import ', 'from '))]
    for line in import_lines[:10]:  # Check first 10 imports
        # Just note them - actual import validation would require execution context
        pass
    
    valid = len(errors) == 0
    trace.log("ck3lens.validate_python", {
        "source": source_desc,
        "code_length": len(code_to_check)
    }, {"valid": valid, "errors": len(errors), "warnings": len(warnings)})
    
    return {
        "valid": valid,
        "errors": errors,
        "warnings": warnings,
        "imports_found": len(import_lines),
        "note": "For full type checking, use get_errors tool on saved files."
    }


# ============================================================================
# Semantic Analysis Tools (Autocomplete, Hover, Reference Validation)
# ============================================================================

@mcp.tool()
def ck3_validate_references(
    content: str,
    filename: str = "inline.txt"
) -> dict:
    """
    Validate all references in CK3 script content.
    
    Checks that all symbol references (traits, events, decisions, etc.)
    exist in the symbol database. Returns diagnostics for undefined references
    with suggestions for similar symbols.
    
    Args:
        content: CK3 script content to validate
        filename: For context in error messages
    
    Returns:
        {
            "success": bool (true if no errors),
            "errors": [...],
            "warnings": [...]
        }
    """
    from ck3lens.semantic import validate_content
    
    session = _get_session()
    trace = _get_trace()
    playset_id = _get_playset_id()
    
    result = validate_content(
        content=content,
        db_path=session.db_path,
        playset_id=playset_id,
        filename=filename
    )
    
    trace.log("ck3lens.validate_references", {
        "filename": filename,
        "content_length": len(content)
    }, {
        "success": result["success"],
        "errors": len(result["errors"]),
        "warnings": len(result["warnings"])
    })
    
    return result


@mcp.tool()
def ck3_get_completions(
    content: str,
    line: int,
    column: int,
    filename: str = "inline.txt"
) -> dict:
    """
    Get autocomplete suggestions at cursor position.
    
    Provides intelligent completions based on context:
    - After 'has_trait = ' suggests traits
    - After 'trigger_event = ' suggests events
    - Block names suggest scope changers and keywords
    
    Args:
        content: Full file content
        line: 1-based line number
        column: 0-based column position
        filename: For context
    
    Returns:
        {
            "completions": [
                {
                    "label": "brave",
                    "kind": "symbol",
                    "detail": "trait (vanilla)",
                    "documentation": "Defined in: common/traits/00_traits.txt",
                    "insertText": "brave"
                },
                ...
            ]
        }
    """
    from ck3lens.semantic import get_completions
    
    session = _get_session()
    trace = _get_trace()
    playset_id = _get_playset_id()
    
    completions = get_completions(
        content=content,
        line=line,
        column=column,
        db_path=session.db_path,
        playset_id=playset_id
    )
    
    trace.log("ck3lens.get_completions", {
        "line": line,
        "column": column
    }, {
        "completions_count": len(completions)
    })
    
    return {"completions": completions}


@mcp.tool()
def ck3_get_hover(
    content: str,
    line: int,
    column: int,
    filename: str = "inline.txt"
) -> dict:
    """
    Get hover documentation for symbol at cursor position.
    
    Returns markdown-formatted documentation including:
    - Symbol name and type
    - Source mod (vanilla or mod name)
    - Definition file and line number
    
    Args:
        content: Full file content
        line: 1-based line number
        column: 0-based column position
        filename: For context
    
    Returns:
        {
            "content": "**brave**\n\nType: `trait`\n\nSource: `vanilla`\n\nFile: `common/traits/00_traits.txt`",
            "range": {"line": 5, "column": 10, "end_line": 5, "end_column": 15}
        }
        or null if no symbol at position
    """
    from ck3lens.semantic import get_hover
    
    session = _get_session()
    trace = _get_trace()
    playset_id = _get_playset_id()
    
    result = get_hover(
        content=content,
        line=line,
        column=column,
        db_path=session.db_path,
        playset_id=playset_id
    )
    
    trace.log("ck3lens.get_hover", {
        "line": line,
        "column": column
    }, {
        "found": result is not None
    })
    
    return result or {"content": None}


@mcp.tool()
def ck3_get_definition(
    content: str,
    line: int,
    column: int,
    filename: str = "inline.txt"
) -> dict:
    """
    Get definition location for symbol at cursor position.
    
    Returns file path and line number where the symbol is defined.
    
    Args:
        content: Full file content
        line: 1-based line number
        column: 0-based column position
        filename: For context
    
    Returns:
        {
            "file": "common/traits/00_traits.txt",
            "line": 42,
            "mod": "vanilla"
        }
        or null if not found
    """
    from ck3lens.semantic import SemanticAnalyzer
    
    session = _get_session()
    trace = _get_trace()
    playset_id = _get_playset_id()
    
    analyzer = SemanticAnalyzer(session.db_path, playset_id)
    try:
        location = analyzer.get_definition(content, line, column, filename)
        
        trace.log("ck3lens.get_definition", {
            "line": line,
            "column": column
        }, {
            "found": location is not None
        })
        
        if location:
            return {
                "file": location.file_path,
                "line": location.line,
                "mod": location.mod
            }
        return {"file": None}
    finally:
        analyzer.close()


# ============================================================================
# Git Operations
# ============================================================================

@mcp.tool()
def ck3_git_status(mod_name: str) -> dict:
    """
    Get git status for a live mod.
    
    Args:
        mod_name: Name of the live mod
    
    Returns:
        Git status (staged, unstaged, untracked files)
    """
    session = _get_session()
    trace = _get_trace()
    
    result = git_ops.git_status(session, mod_name)
    
    trace.log("ck3lens.git_status", {"mod_name": mod_name}, {"success": result.get("success", False)})
    
    return result


@mcp.tool()
def ck3_git_diff(
    mod_name: str,
    file_path: Optional[str] = None,
    staged: bool = False
) -> dict:
    """
    Get git diff for a live mod.
    
    Args:
        mod_name: Name of the live mod
        file_path: Optional specific file to diff
        staged: If True, show staged changes
    
    Returns:
        Diff output
    """
    session = _get_session()
    trace = _get_trace()
    
    result = git_ops.git_diff(session, mod_name, file_path, staged)
    
    trace.log("ck3lens.git_diff", {"mod_name": mod_name, "file_path": file_path}, {"success": result.get("success", False)})
    
    return result


@mcp.tool()
def ck3_git_add(
    mod_name: str,
    paths: Optional[list[str]] = None
) -> dict:
    """
    Stage files for commit in a live mod.
    
    Args:
        mod_name: Name of the live mod
        paths: List of paths to stage (default: all changes)
    
    Returns:
        Success status
    """
    session = _get_session()
    trace = _get_trace()
    
    result = git_ops.git_add(session, mod_name, paths)
    
    trace.log("ck3lens.git_add", {"mod_name": mod_name, "paths": paths}, {"success": result.get("success", False)})
    
    return result


@mcp.tool()
def ck3_git_commit(
    mod_name: str,
    message: str
) -> dict:
    """
    Commit staged changes in a live mod.
    
    Args:
        mod_name: Name of the live mod
        message: Commit message
    
    Returns:
        Commit info (hash, etc.)
    """
    session = _get_session()
    trace = _get_trace()
    
    result = git_ops.git_commit(session, mod_name, message)
    
    trace.log("ck3lens.git_commit", {"mod_name": mod_name, "message": message[:50]}, {"success": result.get("success", False)})
    
    return result


@mcp.tool()
def ck3_git_push(mod_name: str) -> dict:
    """
    Push commits to remote for a live mod.
    
    Args:
        mod_name: Name of the live mod
    
    Returns:
        Push result
    """
    session = _get_session()
    trace = _get_trace()
    
    result = git_ops.git_push(session, mod_name)
    
    trace.log("ck3lens.git_push", {"mod_name": mod_name}, {"success": result.get("success", False)})
    
    return result


@mcp.tool()
def ck3_git_pull(mod_name: str) -> dict:
    """
    Pull latest changes from remote for a live mod.
    
    Args:
        mod_name: Name of the live mod
    
    Returns:
        Pull result
    """
    session = _get_session()
    trace = _get_trace()
    
    result = git_ops.git_pull(session, mod_name)
    
    trace.log("ck3lens.git_pull", {"mod_name": mod_name}, {"success": result.get("success", False)})
    
    return result


@mcp.tool()
def ck3_git_log(
    mod_name: str,
    limit: int = 10,
    file_path: Optional[str] = None
) -> dict:
    """
    Get git log for a live mod.
    
    Args:
        mod_name: Name of the live mod
        limit: Max commits to return
        file_path: Optional path to filter commits
    
    Returns:
        List of commits
    """
    session = _get_session()
    trace = _get_trace()
    
    result = git_ops.git_log(session, mod_name, limit, file_path)
    
    trace.log("ck3lens.git_log", {"mod_name": mod_name, "limit": limit}, {"success": result.get("success", False)})
    
    return result


# ============================================================================
# Playset Management Tools
# ============================================================================

@mcp.tool()
def ck3_get_active_playset() -> dict:
    """
    Get information about the currently active playset.
    
    Returns:
        Playset details including name, mod count, and mod list with load order
    """
    db = _get_db()
    trace = _get_trace()
    playset_id = _get_playset_id()
    
    # Get playset info
    playset = db.conn.execute("""
        SELECT playset_id, name, description, is_active, created_at, updated_at
        FROM playsets WHERE playset_id = ?
    """, (playset_id,)).fetchone()
    
    if not playset:
        return {"error": "No active playset found"}
    
    # Get mods in playset with load order
    mods = db.conn.execute("""
        SELECT pm.load_order_index, mp.name, mp.workshop_id, cv.file_count
        FROM playset_mods pm
        JOIN content_versions cv ON pm.content_version_id = cv.content_version_id
        JOIN mod_packages mp ON cv.mod_package_id = mp.mod_package_id
        WHERE pm.playset_id = ? AND pm.enabled = 1
        ORDER BY pm.load_order_index
    """, (playset_id,)).fetchall()
    
    result = {
        "playset_id": playset[0],
        "name": playset[1],
        "description": playset[2],
        "is_active": bool(playset[3]),
        "mod_count": len(mods),
        "mods": [
            {"load_order": m[0], "name": m[1], "workshop_id": m[2], "file_count": m[3]}
            for m in mods
        ]
    }
    
    trace.log("ck3lens.get_active_playset", {}, {"mod_count": len(mods)})
    
    return result


@mcp.tool()
def ck3_list_playsets() -> dict:
    """
    List all available playsets in the database.
    
    Returns:
        List of playsets with basic info
    """
    db = _get_db()
    trace = _get_trace()
    
    playsets = db.conn.execute("""
        SELECT p.playset_id, p.name, p.description, p.is_active,
               COUNT(pm.content_version_id) as mod_count
        FROM playsets p
        LEFT JOIN playset_mods pm ON p.playset_id = pm.playset_id AND pm.enabled = 1
        GROUP BY p.playset_id
        ORDER BY p.is_active DESC, p.updated_at DESC
    """).fetchall()
    
    result = {
        "playsets": [
            {
                "playset_id": p[0],
                "name": p[1],
                "description": p[2],
                "is_active": bool(p[3]),
                "mod_count": p[4]
            }
            for p in playsets
        ]
    }
    
    trace.log("ck3lens.list_playsets", {}, {"count": len(playsets)})
    
    return result


@mcp.tool()
def ck3_switch_playset(playset_id: int) -> dict:
    """
    Switch the active playset (change the lens).
    
    This instantly changes which playset is used for all lens-scoped operations.
    Like changing glasses - you see the same database through a different filter.
    
    The playset itself is not modified - this just changes which playset is marked
    as "active" for queries.
    
    Args:
        playset_id: ID of the playset to switch to
    
    Returns:
        Success status with new active playset info
    """
    db = _get_db()
    trace = _get_trace()
    
    # Verify playset exists
    playset = db.conn.execute(
        "SELECT playset_id, name FROM playsets WHERE playset_id = ?",
        (playset_id,)
    ).fetchone()
    
    if not playset:
        return {"success": False, "error": f"Playset {playset_id} not found"}
    
    # Update is_active flags
    db.conn.execute("UPDATE playsets SET is_active = 0")
    db.conn.execute("UPDATE playsets SET is_active = 1 WHERE playset_id = ?", (playset_id,))
    db.conn.commit()
    
    # Invalidate cached lens
    db.invalidate_lens_cache()
    
    trace.log("ck3lens.switch_playset", {
        "playset_id": playset_id,
        "playset_name": playset[1]
    }, {"success": True})
    
    return {
        "success": True,
        "message": f"Switched to playset: {playset[1]}",
        "playset_id": playset_id,
        "playset_name": playset[1]
    }


@mcp.tool()
def ck3_search_mods(
    query: str,
    search_by: Literal["name", "workshop_id", "any"] = "any",
    fuzzy: bool = True,
    limit: int = 20
) -> dict:
    """
    Search for mods in the database by name, workshop ID, or both.
    
    Supports fuzzy matching for name searches (handles abbreviations).
    
    Args:
        query: Search term (mod name, abbreviation, or workshop ID)
        search_by: Search field - "name", "workshop_id", or "any"
        fuzzy: Enable fuzzy name matching (catches abbreviations like "EPE" for "Ethnicities and Portraits Expanded")
        limit: Maximum results
    
    Returns:
        List of matching mods with details
    """
    db = _get_db()
    trace = _get_trace()
    
    results = []
    
    if search_by in ("workshop_id", "any") and query.isdigit():
        # Exact workshop ID match
        rows = db.conn.execute("""
            SELECT mp.mod_package_id, mp.name, mp.workshop_id, mp.source_path,
                   cv.content_version_id, cv.file_count
            FROM mod_packages mp
            LEFT JOIN content_versions cv ON cv.mod_package_id = mp.mod_package_id
            WHERE mp.workshop_id = ?
            ORDER BY cv.ingested_at DESC
        """, (query,)).fetchall()
        for r in rows:
            results.append({
                "mod_package_id": r[0], "name": r[1], "workshop_id": r[2],
                "source_path": r[3], "content_version_id": r[4], "file_count": r[5],
                "match_type": "exact_id"
            })
    
    if search_by in ("name", "any"):
        # Name matching
        patterns = [
            (f"%{query}%", "contains"),
        ]
        
        if fuzzy:
            # Abbreviation matching: "EPE" -> "E%P%E%"
            if query.isupper() and len(query) <= 5:
                abbrev_pattern = "%".join(query) + "%"
                patterns.append((abbrev_pattern, "abbreviation"))
            
            # Token matching for underscore/space separated
            tokens = query.replace("_", " ").split()
            if len(tokens) > 1:
                token_pattern = "%".join(tokens)
                patterns.append((f"%{token_pattern}%", "tokens"))
        
        seen_ids = {r["mod_package_id"] for r in results}
        
        for pattern, match_type in patterns:
            rows = db.conn.execute("""
                SELECT mp.mod_package_id, mp.name, mp.workshop_id, mp.source_path,
                       cv.content_version_id, cv.file_count
                FROM mod_packages mp
                LEFT JOIN content_versions cv ON cv.mod_package_id = mp.mod_package_id
                WHERE LOWER(mp.name) LIKE LOWER(?)
                ORDER BY cv.ingested_at DESC
                LIMIT ?
            """, (pattern, limit)).fetchall()
            
            for r in rows:
                if r[0] not in seen_ids:
                    seen_ids.add(r[0])
                    results.append({
                        "mod_package_id": r[0], "name": r[1], "workshop_id": r[2],
                        "source_path": r[3], "content_version_id": r[4], "file_count": r[5],
                        "match_type": match_type
                    })
    
    trace.log("ck3lens.search_mods", {"query": query, "search_by": search_by, "fuzzy": fuzzy},
              {"result_count": len(results)})
    
    return {"results": results[:limit], "query": query}


@mcp.tool()
def ck3_add_mod_to_playset(
    mod_identifier: str,
    position: Optional[int] = None,
    before_mod: Optional[str] = None,
    after_mod: Optional[str] = None
) -> dict:
    """
    Add a mod to the active playset, with full ingestion and symbol extraction.
    
    This is a comprehensive operation that:
    1. Finds the mod (by workshop ID, name, or path)
    2. Ingests files if not already indexed
    3. Extracts symbols for search
    4. Adds to playset at specified position
    
    Args:
        mod_identifier: Workshop ID, mod name, or filesystem path
        position: Explicit load order position (0-indexed)
        before_mod: Insert before this mod (by name or workshop ID)
        after_mod: Insert after this mod (by name or workshop ID)
    
    Returns:
        Success status with mod details
    """
    db = _get_db()
    trace = _get_trace()
    playset_id = _get_playset_id()
    
    # Import ck3raven modules for ingestion
    from ck3raven.db.ingest import ingest_mod, get_or_create_mod_package
    from ck3raven.parser import parse_source
    from ck3raven.db.symbols import extract_symbols_from_ast
    
    # Step 1: Find the mod
    mod_path = None
    workshop_id = None
    mod_name = None
    
    # Check if it's a workshop ID
    if mod_identifier.isdigit():
        workshop_id = mod_identifier
        # Check if already in database
        existing = db.conn.execute(
            "SELECT mod_package_id, name, source_path FROM mod_packages WHERE workshop_id = ?",
            (workshop_id,)
        ).fetchone()
        if existing:
            mod_name = existing[1]
            mod_path = Path(existing[2]) if existing[2] else None
        else:
            # Look for it in workshop folder
            workshop_path = Path("C:/Program Files (x86)/Steam/steamapps/workshop/content/1158310") / workshop_id
            if workshop_path.exists():
                mod_path = workshop_path
                mod_name = f"Workshop Mod {workshop_id}"
    
    # Check if it's a path
    elif "/" in mod_identifier or "\\" in mod_identifier:
        mod_path = Path(mod_identifier)
        if mod_path.exists():
            mod_name = mod_path.name
            # Try to extract workshop ID from path
            if "1158310" in str(mod_path):
                parts = str(mod_path).split("1158310")
                if len(parts) > 1:
                    potential_id = parts[1].strip("/\\").split("/")[0].split("\\")[0]
                    if potential_id.isdigit():
                        workshop_id = potential_id
    
    # Otherwise search by name
    else:
        search_result = db.conn.execute("""
            SELECT mod_package_id, name, workshop_id, source_path
            FROM mod_packages WHERE LOWER(name) LIKE LOWER(?)
            ORDER BY mod_package_id LIMIT 1
        """, (f"%{mod_identifier}%",)).fetchone()
        if search_result:
            mod_name = search_result[1]
            workshop_id = search_result[2]
            mod_path = Path(search_result[3]) if search_result[3] else None
    
    if not mod_path or not mod_path.exists():
        return {"error": f"Could not find mod: {mod_identifier}"}
    
    # Step 2: Ingest if needed
    mod_pkg, ingest_result = ingest_mod(
        conn=db.conn,
        mod_path=mod_path,
        name=mod_name,
        workshop_id=workshop_id,
        force=False
    )
    
    # Get content_version_id
    cv_row = db.conn.execute("""
        SELECT content_version_id, file_count FROM content_versions
        WHERE mod_package_id = ? ORDER BY ingested_at DESC LIMIT 1
    """, (mod_pkg.mod_package_id,)).fetchone()
    
    if not cv_row:
        return {"error": "Failed to ingest mod files"}
    
    content_version_id = cv_row[0]
    file_count = cv_row[1]
    
    # Step 3: Extract symbols if not already done
    existing_symbols = db.conn.execute(
        "SELECT COUNT(*) FROM symbols WHERE content_version_id = ?",
        (content_version_id,)
    ).fetchone()[0]
    
    symbols_extracted = 0
    if existing_symbols == 0:
        # Extract symbols
        rows = db.conn.execute("""
            SELECT f.file_id, f.relpath, f.content_hash FROM files f
            WHERE f.content_version_id = ? AND f.relpath LIKE '%.txt'
        """, (content_version_id,)).fetchall()
        
        batch = []
        for row in rows:
            content_row = db.conn.execute(
                "SELECT COALESCE(content_text, content_blob) as content FROM file_contents WHERE content_hash = ?",
                (row[2],)
            ).fetchone()
            if not content_row:
                continue
            
            content = content_row[0]
            if isinstance(content, bytes):
                content = content.decode('utf-8', errors='replace')
            if content.startswith('\ufeff'):
                content = content[1:]
            
            try:
                ast = parse_source(content, filename=row[1])
                for sym in extract_symbols_from_ast(ast.to_dict(), row[1], row[2]):
                    batch.append((sym.kind, sym.name, sym.scope, None, row[0], 
                                 content_version_id, None, sym.line, None))
            except:
                pass
        
        if batch:
            db.conn.executemany("""
                INSERT INTO symbols (symbol_type, name, scope, defining_ast_id, defining_file_id,
                                    content_version_id, ast_node_path, line_number, metadata_json)
                VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)
            """, batch)
        symbols_extracted = len(batch)
    else:
        symbols_extracted = existing_symbols
    
    # Step 4: Determine load order position
    if before_mod:
        # Find the mod to insert before
        ref_row = db.conn.execute("""
            SELECT pm.load_order_index FROM playset_mods pm
            JOIN content_versions cv ON pm.content_version_id = cv.content_version_id
            JOIN mod_packages mp ON cv.mod_package_id = mp.mod_package_id
            WHERE pm.playset_id = ? AND (mp.name LIKE ? OR mp.workshop_id = ?)
        """, (playset_id, f"%{before_mod}%", before_mod)).fetchone()
        if ref_row:
            position = ref_row[0]
    elif after_mod:
        # Find the mod to insert after
        ref_row = db.conn.execute("""
            SELECT pm.load_order_index FROM playset_mods pm
            JOIN content_versions cv ON pm.content_version_id = cv.content_version_id
            JOIN mod_packages mp ON cv.mod_package_id = mp.mod_package_id
            WHERE pm.playset_id = ? AND (mp.name LIKE ? OR mp.workshop_id = ?)
        """, (playset_id, f"%{after_mod}%", after_mod)).fetchone()
        if ref_row:
            position = ref_row[0] + 1
    
    if position is None:
        # Add at end
        max_order = db.conn.execute(
            "SELECT MAX(load_order_index) FROM playset_mods WHERE playset_id = ?",
            (playset_id,)
        ).fetchone()[0]
        position = (max_order or -1) + 1
    
    # Shift existing mods if inserting in the middle
    db.conn.execute("""
        UPDATE playset_mods SET load_order_index = load_order_index + 1
        WHERE playset_id = ? AND load_order_index >= ?
    """, (playset_id, position))
    
    # Insert the new mod
    db.conn.execute("""
        INSERT OR REPLACE INTO playset_mods (playset_id, content_version_id, load_order_index, enabled)
        VALUES (?, ?, ?, 1)
    """, (playset_id, content_version_id, position))
    
    db.conn.commit()
    
    trace.log("ck3lens.add_mod_to_playset", {
        "mod_identifier": mod_identifier, "position": position
    }, {
        "mod_name": mod_name, "files": file_count, "symbols": symbols_extracted
    })
    
    return {
        "success": True,
        "mod_name": mod_name,
        "workshop_id": workshop_id,
        "content_version_id": content_version_id,
        "load_order_position": position,
        "files_indexed": file_count,
        "symbols_extracted": symbols_extracted,
        "was_already_indexed": ingest_result.stats.content_reused if ingest_result else False
    }


@mcp.tool()
def ck3_remove_mod_from_playset(
    mod_identifier: str
) -> dict:
    """
    Remove a mod from the active playset.
    
    Note: This only removes from the playset, not from the database.
    The mod's files and symbols remain indexed for potential re-use.
    
    Args:
        mod_identifier: Workshop ID or mod name
    
    Returns:
        Success status
    """
    db = _get_db()
    trace = _get_trace()
    playset_id = _get_playset_id()
    
    # Find the content_version_id for this mod
    if mod_identifier.isdigit():
        row = db.conn.execute("""
            SELECT pm.content_version_id, mp.name, pm.load_order_index
            FROM playset_mods pm
            JOIN content_versions cv ON pm.content_version_id = cv.content_version_id
            JOIN mod_packages mp ON cv.mod_package_id = mp.mod_package_id
            WHERE pm.playset_id = ? AND mp.workshop_id = ?
        """, (playset_id, mod_identifier)).fetchone()
    else:
        row = db.conn.execute("""
            SELECT pm.content_version_id, mp.name, pm.load_order_index
            FROM playset_mods pm
            JOIN content_versions cv ON pm.content_version_id = cv.content_version_id
            JOIN mod_packages mp ON cv.mod_package_id = mp.mod_package_id
            WHERE pm.playset_id = ? AND LOWER(mp.name) LIKE LOWER(?)
        """, (playset_id, f"%{mod_identifier}%")).fetchone()
    
    if not row:
        return {"error": f"Mod not found in playset: {mod_identifier}"}
    
    content_version_id = row[0]
    mod_name = row[1]
    removed_position = row[2]
    
    # Remove from playset
    db.conn.execute("""
        DELETE FROM playset_mods WHERE playset_id = ? AND content_version_id = ?
    """, (playset_id, content_version_id))
    
    # Shift remaining mods down
    db.conn.execute("""
        UPDATE playset_mods SET load_order_index = load_order_index - 1
        WHERE playset_id = ? AND load_order_index > ?
    """, (playset_id, removed_position))
    
    db.conn.commit()
    
    trace.log("ck3lens.remove_mod_from_playset", {"mod_identifier": mod_identifier},
              {"mod_name": mod_name, "position": removed_position})
    
    return {
        "success": True,
        "mod_name": mod_name,
        "removed_from_position": removed_position
    }


@mcp.tool()
def ck3_create_playset_from_indexed(
    playset_name: str | None = None,
    playset_file: str | None = None,
    set_active: bool = True
) -> dict:
    """
    Create a playset from already-indexed content in the database.
    
    This links existing content_versions to a new playset. Use this after
    running the daemon build, which ingests mods but doesn't create playsets.
    
    If playset_file is provided, it reads the active_mod_paths.json format:
    {
        "playset_name": "...",
        "paths": [
            {"name": "ModName", "steam_id": "123", "load_order": 0, "enabled": true},
            ...
        ]
    }
    
    If no file is provided, creates a playset with ALL indexed mods in
    the order they were ingested (vanilla first).
    
    Args:
        playset_name: Name for the playset (default: from file or "Default Playset")
        playset_file: Path to active_mod_paths.json (optional)
        set_active: Whether to make this the active playset (default: True)
    
    Returns:
        Playset creation result with linked mods count
    """
    import json
    db = _get_db()
    trace = _get_trace()
    
    # Load playset file if provided
    mod_entries = []
    final_name = playset_name
    
    if playset_file:
        path = Path(playset_file)
        if not path.exists():
            return {"error": f"File not found: {playset_file}"}
        with open(path, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        if not final_name and "playset_name" in data:
            final_name = data["playset_name"]
        
        if "paths" in data:
            mod_entries = data["paths"]
    
    if not final_name:
        final_name = "Default Playset"
    
    # Get vanilla content_version_id and vanilla_version_id
    vanilla_cv = db.conn.execute("""
        SELECT content_version_id, vanilla_version_id 
        FROM content_versions WHERE kind = 'vanilla' 
        ORDER BY ingested_at DESC LIMIT 1
    """).fetchone()
    
    if not vanilla_cv:
        return {"error": "No vanilla content indexed. Run daemon build first."}
    
    vanilla_cv_id = vanilla_cv[0]
    vanilla_version_id = vanilla_cv[1]
    
    # Create the playset with vanilla_version_id
    db.conn.execute("""
        INSERT INTO playsets (name, vanilla_version_id, is_active, created_at, updated_at)
        VALUES (?, ?, ?, datetime('now'), datetime('now'))
    """, (final_name, vanilla_version_id, 1 if set_active else 0))
    db.conn.commit()
    
    playset_id = db.conn.execute("SELECT last_insert_rowid()").fetchone()[0]
    
    # Deactivate other playsets if setting this one active
    if set_active:
        db.conn.execute("""
            UPDATE playsets SET is_active = 0 WHERE playset_id != ?
        """, (playset_id,))
    
    # Add vanilla as load_order -1 (before all mods)
    db.conn.execute("""
        INSERT INTO playset_mods (playset_id, content_version_id, load_order_index, enabled)
        VALUES (?, ?, -1, 1)
    """, (playset_id, vanilla_cv_id))
    
    linked_count = 1  # Vanilla
    skipped = []
    
    if mod_entries:
        # Link mods from the playset file
        for entry in mod_entries:
            if not entry.get("enabled", True):
                continue
            
            mod_name = entry.get("name", "")
            steam_id = entry.get("steam_id", "")
            mod_path = entry.get("path", "")
            load_order = entry.get("load_order", 0)
            
            cv_row = None
            
            # Try steam_id first (most reliable for workshop mods)
            if steam_id:
                cv_row = db.conn.execute("""
                    SELECT cv.content_version_id, mp.name
                    FROM content_versions cv
                    JOIN mod_packages mp ON cv.mod_package_id = mp.mod_package_id
                    WHERE mp.workshop_id = ?
                    ORDER BY cv.ingested_at DESC LIMIT 1
                """, (steam_id,)).fetchone()
            
            # If not found by steam_id, try by source_path (for local mods)
            if not cv_row and mod_path:
                cv_row = db.conn.execute("""
                    SELECT cv.content_version_id, mp.name
                    FROM content_versions cv
                    JOIN mod_packages mp ON cv.mod_package_id = mp.mod_package_id
                    WHERE mp.source_path = ?
                    ORDER BY cv.ingested_at DESC LIMIT 1
                """, (mod_path,)).fetchone()
            
            # Last resort: try by exact name
            if not cv_row:
                cv_row = db.conn.execute("""
                    SELECT cv.content_version_id, mp.name
                    FROM content_versions cv
                    JOIN mod_packages mp ON cv.mod_package_id = mp.mod_package_id
                    WHERE mp.name = ?
                    ORDER BY cv.ingested_at DESC LIMIT 1
                """, (mod_name,)).fetchone()
            
            if not cv_row:
                skipped.append({"name": mod_name, "steam_id": steam_id, "reason": "not_in_database"})
                continue
            
            # Add to playset - use load_order directly from JSON
            db.conn.execute("""
                INSERT INTO playset_mods (playset_id, content_version_id, load_order_index, enabled)
                VALUES (?, ?, ?, 1)
            """, (playset_id, cv_row[0], load_order))
            
            linked_count += 1
    else:
        # No file provided - link ALL indexed mods
        all_mods = db.conn.execute("""
            SELECT cv.content_version_id, mp.name
            FROM content_versions cv
            JOIN mod_packages mp ON cv.mod_package_id = mp.mod_package_id
            WHERE cv.kind = 'mod'
            ORDER BY cv.ingested_at ASC
        """).fetchall()
        
        for idx, row in enumerate(all_mods, start=1):
            db.conn.execute("""
                INSERT INTO playset_mods (playset_id, content_version_id, load_order_index, enabled)
                VALUES (?, ?, ?, 1)
            """, (playset_id, row[0], idx))
            linked_count += 1
    
    db.conn.commit()
    
    # Update global playset_id
    if set_active:
        global _playset_id
        _playset_id = playset_id
    
    trace.log("ck3lens.create_playset_from_indexed", {
        "source": playset_file or "all_indexed",
        "playset_name": final_name
    }, {
        "playset_id": playset_id,
        "linked": linked_count,
        "skipped": len(skipped)
    })
    
    return {
        "success": True,
        "playset_id": playset_id,
        "playset_name": final_name,
        "vanilla_version_id": vanilla_version_id,
        "mods_linked": linked_count,
        "mods_skipped": skipped if skipped else None,
        "is_active": set_active
    }


@mcp.tool()
def ck3_import_playset_from_launcher(
    launcher_json_path: str | None = None,
    launcher_json_content: str | None = None,
    playset_name: str | None = None,
    local_mod_paths: list[str] | None = None,
    set_active: bool = True
) -> dict:
    """
    Import a playset from CK3 Launcher JSON export.
    
    The launcher JSON can be exported from Paradox Launcher:
    Settings > Export Playset (creates .json file)
    
    Args:
        launcher_json_path: Path to the launcher JSON file
        launcher_json_content: Raw JSON content (alternative to path)
        playset_name: Override name (default: from JSON or "Imported Playset")
        local_mod_paths: Additional local mod paths to add at end of load order
        set_active: Whether to make this the active playset (default: True)
    
    Returns:
        Playset creation result with linked mods count
    """
    import json
    db = _get_db()
    trace = _get_trace()
    
    # Load JSON
    if launcher_json_path:
        path = Path(launcher_json_path)
        if not path.exists():
            return {"error": f"File not found: {launcher_json_path}"}
        with open(path, 'r', encoding='utf-8') as f:
            data = json.load(f)
    elif launcher_json_content:
        data = json.loads(launcher_json_content)
    else:
        return {"error": "Must provide launcher_json_path or launcher_json_content"}
    
    # Extract playset name
    final_name = playset_name
    if not final_name:
        if "name" in data:
            final_name = data["name"]
        elif "playset" in data and "name" in data["playset"]:
            final_name = data["playset"]["name"]
        else:
            final_name = "Imported Playset"
    
    # Extract mods from JSON
    mod_entries = []
    if "mods" in data:
        mod_entries = data["mods"]
    elif "playset" in data and "mods" in data["playset"]:
        mod_entries = data["playset"]["mods"]
    
    # Create the playset
    db.conn.execute("""
        INSERT INTO playsets (name, created_at) VALUES (?, datetime('now'))
    """, (final_name,))
    db.conn.commit()
    
    playset_id = db.conn.execute("SELECT last_insert_rowid()").fetchone()[0]
    
    # Process mods
    linked_count = 0
    skipped = []
    load_order = 1  # Start at 1 (0 is typically vanilla)
    
    for mod in mod_entries:
        # Get steam_id from mod entry
        steam_id = None
        if "steamId" in mod:
            steam_id = str(mod["steamId"])
        elif "steam_id" in mod:
            steam_id = str(mod["steam_id"])
        elif "id" in mod:
            steam_id = str(mod["id"])
        
        if not steam_id:
            skipped.append({"reason": "no_steam_id", "mod": mod})
            continue
        
        # Find in database by workshop_id
        cv_row = db.conn.execute("""
            SELECT cv.content_version_id, mp.name
            FROM content_versions cv
            JOIN mod_packages mp ON cv.mod_package_id = mp.mod_package_id
            WHERE mp.workshop_id = ?
            ORDER BY cv.ingested_at DESC LIMIT 1
        """, (steam_id,)).fetchone()
        
        if not cv_row:
            mod_name = mod.get("displayName") or mod.get("name") or steam_id
            skipped.append({"steam_id": steam_id, "name": mod_name, "reason": "not_in_database"})
            continue
        
        # Add to playset
        db.conn.execute("""
            INSERT INTO playset_mods (playset_id, content_version_id, load_order_index, enabled)
            VALUES (?, ?, ?, 1)
        """, (playset_id, cv_row[0], load_order))
        
        linked_count += 1
        load_order += 1
    
    # Add local mods at end
    local_linked = 0
    if local_mod_paths:
        for local_path in local_mod_paths:
            path = Path(local_path)
            if not path.exists():
                skipped.append({"path": local_path, "reason": "path_not_found"})
                continue
            
            # Find by source_path
            cv_row = db.conn.execute("""
                SELECT cv.content_version_id, mp.name
                FROM content_versions cv
                JOIN mod_packages mp ON cv.mod_package_id = mp.mod_package_id
                WHERE mp.source_path LIKE ?
                ORDER BY cv.ingested_at DESC LIMIT 1
            """, (f"%{path.name}",)).fetchone()
            
            if cv_row:
                db.conn.execute("""
                    INSERT INTO playset_mods (playset_id, content_version_id, load_order_index, enabled)
                    VALUES (?, ?, ?, 1)
                """, (playset_id, cv_row[0], load_order))
                local_linked += 1
                load_order += 1
            else:
                skipped.append({"path": local_path, "reason": "not_in_database"})
    
    db.conn.commit()
    
    # Set as active if requested
    if set_active:
        global _session
        if _session:
            _session.playset_id = playset_id
    
    trace.log("ck3lens.import_playset_from_launcher", {
        "source": launcher_json_path or "inline_json",
        "playset_name": final_name
    }, {
        "playset_id": playset_id,
        "linked": linked_count,
        "local_linked": local_linked,
        "skipped": len(skipped)
    })
    
    return {
        "success": True,
        "playset_id": playset_id,
        "playset_name": final_name,
        "mods_linked": linked_count,
        "local_mods_linked": local_linked,
        "mods_skipped": skipped if skipped else None,
        "is_active": set_active,
        "next_steps": "Use ck3_add_mod_to_playset to add missing mods after ingesting them"
    }


@mcp.tool()
def ck3_reorder_mod_in_playset(
    mod_identifier: str,
    new_position: int | None = None,
    before_mod: str | None = None,
    after_mod: str | None = None
) -> dict:
    """
    Move a mod to a new position in the active playset's load order.
    
    Args:
        mod_identifier: Workshop ID or mod name to move
        new_position: Target position (0-indexed). 0=first loaded, higher=later
        before_mod: Move before this mod (by name or workshop ID)
        after_mod: Move after this mod (by name or workshop ID)
    
    Returns:
        Success status with old and new positions
    """
    db = _get_db()
    trace = _get_trace()
    playset_id = _get_playset_id()
    
    # Find the mod to move
    if mod_identifier.isdigit():
        row = db.conn.execute("""
            SELECT pm.content_version_id, mp.name, pm.load_order_index
            FROM playset_mods pm
            JOIN content_versions cv ON pm.content_version_id = cv.content_version_id
            JOIN mod_packages mp ON cv.mod_package_id = mp.mod_package_id
            WHERE pm.playset_id = ? AND mp.workshop_id = ?
        """, (playset_id, mod_identifier)).fetchone()
    else:
        row = db.conn.execute("""
            SELECT pm.content_version_id, mp.name, pm.load_order_index
            FROM playset_mods pm
            JOIN content_versions cv ON pm.content_version_id = cv.content_version_id
            JOIN mod_packages mp ON cv.mod_package_id = mp.mod_package_id
            WHERE pm.playset_id = ? AND LOWER(mp.name) LIKE LOWER(?)
        """, (playset_id, f"%{mod_identifier}%")).fetchone()
    
    if not row:
        return {"error": f"Mod not found in playset: {mod_identifier}"}
    
    content_version_id = row[0]
    mod_name = row[1]
    old_position = row[2]
    
    # Determine target position
    target_position = new_position
    
    if before_mod:
        ref_row = db.conn.execute("""
            SELECT pm.load_order_index FROM playset_mods pm
            JOIN content_versions cv ON pm.content_version_id = cv.content_version_id
            JOIN mod_packages mp ON cv.mod_package_id = mp.mod_package_id
            WHERE pm.playset_id = ? AND (mp.name LIKE ? OR mp.workshop_id = ?)
        """, (playset_id, f"%{before_mod}%", before_mod)).fetchone()
        if ref_row:
            target_position = ref_row[0]
    elif after_mod:
        ref_row = db.conn.execute("""
            SELECT pm.load_order_index FROM playset_mods pm
            JOIN content_versions cv ON pm.content_version_id = cv.content_version_id
            JOIN mod_packages mp ON cv.mod_package_id = mp.mod_package_id
            WHERE pm.playset_id = ? AND (mp.name LIKE ? OR mp.workshop_id = ?)
        """, (playset_id, f"%{after_mod}%", after_mod)).fetchone()
        if ref_row:
            target_position = ref_row[0] + 1
    
    if target_position is None:
        return {"error": "Must specify new_position, before_mod, or after_mod"}
    
    if target_position == old_position:
        return {"success": True, "mod_name": mod_name, "position": old_position, "message": "No change needed"}
    
    # Remove from old position
    db.conn.execute("""
        DELETE FROM playset_mods WHERE playset_id = ? AND content_version_id = ?
    """, (playset_id, content_version_id))
    
    # Shift mods to close the gap
    db.conn.execute("""
        UPDATE playset_mods SET load_order_index = load_order_index - 1
        WHERE playset_id = ? AND load_order_index > ?
    """, (playset_id, old_position))
    
    # Adjust target if moving down
    if target_position > old_position:
        target_position -= 1
    
    # Shift mods to make room at target
    db.conn.execute("""
        UPDATE playset_mods SET load_order_index = load_order_index + 1
        WHERE playset_id = ? AND load_order_index >= ?
    """, (playset_id, target_position))
    
    # Insert at target position
    db.conn.execute("""
        INSERT INTO playset_mods (playset_id, content_version_id, load_order_index, enabled)
        VALUES (?, ?, ?, 1)
    """, (playset_id, content_version_id, target_position))
    
    db.conn.commit()
    
    trace.log("ck3lens.reorder_mod", {
        "mod_identifier": mod_identifier
    }, {
        "mod_name": mod_name,
        "old_position": old_position,
        "new_position": target_position
    })
    
    return {
        "success": True,
        "mod_name": mod_name,
        "old_position": old_position,
        "new_position": target_position
    }


# ============================================================================
# Conflict Analysis Tools (Unit-Level)
# ============================================================================

@mcp.tool()
def ck3_scan_unit_conflicts(
    folder_filter: str | None = None,
) -> dict:
    """
    Scan the active playset for unit-level conflicts.
    
    This is a comprehensive scan that:
    1. Extracts all ContributionUnits from parsed ASTs
    2. Groups them into ConflictUnits by unit_key
    3. Computes risk scores and merge capabilities
    
    A "unit" is a separately-resolvable block (decision, trait, on_action, etc.)
    
    Args:
        folder_filter: Optional folder path filter (e.g., "common/on_action")
    
    Returns:
        Scan results with conflict summary
    """
    db = _get_db()
    trace = _get_trace()
    playset_id = _get_playset_id()
    
    try:
        from ck3raven.resolver.conflict_analyzer import scan_playset_conflicts
        
        result = scan_playset_conflicts(
            db.conn,
            playset_id,
            folder_filter=folder_filter,
        )
        
        trace.log("ck3lens.scan_unit_conflicts", 
                  {"folder_filter": folder_filter},
                  {"conflicts_found": result["conflicts_found"]})
        
        return result
        
    except Exception as e:
        return {"error": str(e)}


@mcp.tool()
def ck3_get_conflict_summary() -> dict:
    """
    Get a summary of all unit-level conflicts in the active playset.
    
    Returns:
        Summary with counts by risk level, domain, and resolution status
    """
    db = _get_db()
    playset_id = _get_playset_id()
    
    try:
        from ck3raven.resolver.conflict_analyzer import get_conflict_summary
        
        return get_conflict_summary(db.conn, playset_id)
        
    except Exception as e:
        return {"error": str(e)}


@mcp.tool()
def ck3_list_conflict_units(
    risk_filter: str | None = None,
    domain_filter: str | None = None,
    status_filter: str | None = None,
    limit: int = 50,
    offset: int = 0,
) -> dict:
    """
    List conflict units with optional filters.
    
    Args:
        risk_filter: Filter by risk level (low, med, high)
        domain_filter: Filter by domain (on_action, decision, trait, etc.)
        status_filter: Filter by resolution status (unresolved, resolved, deferred)
        limit: Maximum results to return
        offset: Offset for pagination
    
    Returns:
        List of conflict units with candidates
    """
    db = _get_db()
    playset_id = _get_playset_id()
    
    try:
        from ck3raven.resolver.conflict_analyzer import get_conflict_units
        
        conflicts = get_conflict_units(
            db.conn,
            playset_id,
            risk_filter=risk_filter,
            domain_filter=domain_filter,
            status_filter=status_filter,
            limit=limit,
            offset=offset,
        )
        
        return {
            "playset_id": playset_id,
            "count": len(conflicts),
            "conflicts": conflicts,
        }
        
    except Exception as e:
        return {"error": str(e)}


@mcp.tool()
def ck3_get_conflict_detail(conflict_unit_id: str) -> dict:
    """
    Get detailed information about a specific conflict unit.
    
    Includes full candidate information with file content previews.
    
    Args:
        conflict_unit_id: The conflict unit ID
    
    Returns:
        Detailed conflict information
    """
    db = _get_db()
    
    try:
        from ck3raven.resolver.conflict_analyzer import get_conflict_unit_detail
        
        detail = get_conflict_unit_detail(db.conn, conflict_unit_id)
        
        if not detail:
            return {"error": f"Conflict unit not found: {conflict_unit_id}"}
        
        return detail
        
    except Exception as e:
        return {"error": str(e)}


@mcp.tool()
def ck3_resolve_conflict(
    conflict_unit_id: str,
    decision_type: Literal["winner", "defer"],
    winner_candidate_id: str | None = None,
    notes: str | None = None,
) -> dict:
    """
    Record a resolution decision for a conflict unit.
    
    Args:
        conflict_unit_id: The conflict unit ID
        decision_type: Type of resolution (winner = pick a winner, defer = handle later)
        winner_candidate_id: Required if decision_type is "winner" - the candidate to use
        notes: Optional notes explaining the decision
    
    Returns:
        Resolution result
    """
    import hashlib
    import json
    from datetime import datetime
    
    db = _get_db()
    trace = _get_trace()
    
    # Validate conflict exists
    conflict = db.conn.execute("""
        SELECT unit_key, domain FROM conflict_units WHERE conflict_unit_id = ?
    """, (conflict_unit_id,)).fetchone()
    
    if not conflict:
        return {"error": f"Conflict unit not found: {conflict_unit_id}"}
    
    if decision_type == "winner" and not winner_candidate_id:
        return {"error": "winner_candidate_id is required when decision_type is 'winner'"}
    
    # Validate winner candidate exists
    if winner_candidate_id:
        candidate = db.conn.execute("""
            SELECT source_name FROM conflict_candidates 
            WHERE conflict_unit_id = ? AND candidate_id = ?
        """, (conflict_unit_id, winner_candidate_id)).fetchone()
        
        if not candidate:
            return {"error": f"Candidate not found: {winner_candidate_id}"}
    
    # Create resolution
    resolution_id = hashlib.sha256(f"{conflict_unit_id}:{datetime.now().isoformat()}".encode()).hexdigest()[:16]
    
    db.conn.execute("""
        INSERT INTO resolution_choices 
        (resolution_id, conflict_unit_id, decision_type, winner_candidate_id, notes, applied_at, applied_by)
        VALUES (?, ?, ?, ?, ?, datetime('now'), 'user')
    """, (resolution_id, conflict_unit_id, decision_type, winner_candidate_id, notes))
    
    # Update conflict status
    db.conn.execute("""
        UPDATE conflict_units 
        SET resolution_status = ?, resolution_id = ?
        WHERE conflict_unit_id = ?
    """, ('deferred' if decision_type == 'defer' else 'resolved', resolution_id, conflict_unit_id))
    
    db.conn.commit()
    
    trace.log("ck3lens.resolve_conflict", 
              {"conflict_unit_id": conflict_unit_id, "decision_type": decision_type},
              {"resolution_id": resolution_id})
    
    return {
        "success": True,
        "resolution_id": resolution_id,
        "unit_key": conflict[0],
        "domain": conflict[1],
        "decision_type": decision_type,
        "winner_candidate_id": winner_candidate_id,
    }


@mcp.tool()
def ck3_get_unit_content(
    unit_key: str,
    source_filter: str | None = None,
) -> dict:
    """
    Get the content for all candidates of a unit_key.
    
    Useful for comparing what different mods define for the same unit.
    
    Args:
        unit_key: The unit key (e.g., "on_action:on_yearly_pulse")
        source_filter: Optional filter by source name
    
    Returns:
        All contributions for this unit_key with their content
    """
    db = _get_db()
    playset_id = _get_playset_id()
    
    # Contributions are now per-content_version, so we need to join through
    # playset_mods and vanilla to get only contributions in this playset
    query = """
        WITH playset_contribs AS (
            -- Vanilla contributions
            SELECT 
                cu.contrib_id, cu.content_version_id, cu.file_id,
                cu.domain, cu.unit_key, cu.relpath, cu.line_number,
                cu.merge_behavior, cu.summary, cu.node_hash,
                -1 as load_order_index, 'vanilla' as source_kind, 'vanilla' as source_name
            FROM contribution_units cu
            JOIN content_versions cv ON cu.content_version_id = cv.content_version_id
            JOIN vanilla_versions vv ON cv.vanilla_version_id = vv.vanilla_version_id
            JOIN playsets p ON p.vanilla_version_id = vv.vanilla_version_id
            WHERE p.playset_id = ? AND cv.kind = 'vanilla'
            
            UNION ALL
            
            -- Mod contributions
            SELECT 
                cu.contrib_id, cu.content_version_id, cu.file_id,
                cu.domain, cu.unit_key, cu.relpath, cu.line_number,
                cu.merge_behavior, cu.summary, cu.node_hash,
                pm.load_order_index, 'mod' as source_kind,
                COALESCE(mp.name, 'Unknown Mod') as source_name
            FROM contribution_units cu
            JOIN playset_mods pm ON cu.content_version_id = pm.content_version_id
            JOIN content_versions cv ON cu.content_version_id = cv.content_version_id
            LEFT JOIN mod_packages mp ON cv.mod_package_id = mp.mod_package_id
            WHERE pm.playset_id = ? AND pm.enabled = 1
        )
        SELECT 
            pc.contrib_id, pc.content_version_id, pc.file_id,
            pc.domain, pc.relpath, pc.line_number, pc.merge_behavior, pc.summary,
            pc.load_order_index, pc.source_kind, pc.source_name,
            fc.content_text
        FROM playset_contribs pc
        LEFT JOIN files f ON pc.file_id = f.file_id
        LEFT JOIN file_contents fc ON f.content_hash = fc.content_hash
        WHERE pc.unit_key = ?
    """
    params = [playset_id, playset_id, unit_key]
    
    if source_filter:
        query += " AND (pc.source_kind = ? OR LOWER(pc.source_name) LIKE LOWER(?))"
        params.extend([source_filter, f"%{source_filter}%"])
    
    query += " ORDER BY load_order_index"
    
    contributions = []
    for row in db.conn.execute(query, params).fetchall():
        contributions.append({
            "contrib_id": row[0],
            "content_version_id": row[1],
            "file_id": row[2],
            "domain": row[3],
            "relpath": row[4],
            "line_number": row[5],
            "merge_behavior": row[6],
            "summary": row[7],
            "load_order_index": row[8],
            "source_kind": row[9],
            "source_name": row[10],
            "content": row[11][:5000] if row[11] else None,  # Limit content preview
        })
    
    return {
        "unit_key": unit_key,
        "count": len(contributions),
        "contributions": contributions,
    }


# ============================================================================
# General Search Tools
# ============================================================================

@mcp.tool()
def ck3_search_files(
    pattern: str,
    source_filter: Optional[str] = None,
    limit: int = 100,
    no_lens: bool = False
) -> dict:
    """
    Search for files by path pattern.
    
    Use this when you need to find files by name or path pattern,
    NOT for symbol/definition search (use ck3_search_symbols for that).
    
    Args:
        pattern: SQL LIKE pattern for file path (e.g., "%on_action%" or "common/traits/%")
        source_filter: Filter by source ("vanilla", mod name, or mod ID)
        limit: Maximum results to return
        no_lens: If True, search ALL content (not just active playset)
    
    Returns:
        List of matching files with source info
    """
    db = _get_db()
    trace = _get_trace()
    lens = _get_lens(no_lens=no_lens)
    
    files = db.search_files(lens, pattern, source_filter, limit)
    
    trace.log("ck3lens.search_files", {
        "pattern": pattern,
        "source_filter": source_filter,
        "no_lens": no_lens
    }, {"count": len(files)})
    
    return {
        "pattern": pattern, 
        "count": len(files), 
        "files": files,
        "lens": lens.playset_name if lens else "ALL CONTENT (no lens)"
    }


@mcp.tool()
def ck3_search_content(
    query: str,
    file_pattern: Optional[str] = None,
    source_filter: Optional[str] = None,
    limit: int = 50,
    verbose: bool = False,
    no_lens: bool = False
) -> dict:
    """
    Search file contents for text matches (grep-style).
    
    Returns line numbers and snippets for EACH match within files.
    
    Args:
        query: Text to search for (case-insensitive substring match)
        file_pattern: SQL LIKE pattern to limit which files are searched
        source_filter: Filter by source ("vanilla", mod name, or mod ID)
        limit: Maximum files to return
        verbose: If True, return ALL matches per file (default: max 5 per file)
        no_lens: If True, search ALL content (not just active playset)
    
    Returns:
        List of files with line-by-line match details:
        {
            "file_id": 123,
            "relpath": "common/traits/00_traits.txt",
            "match_count": 15,
            "matches": [
                {"line": 45, "snippet": "...brave = {..."},
                {"line": 234, "snippet": "...has_trait = brave..."}
            ],
            "truncated": true  # if more matches exist
        }
    """
    db = _get_db()
    trace = _get_trace()
    lens = _get_lens(no_lens=no_lens)
    
    results = db.search_content(
        lens=lens,
        query=query,
        file_pattern=file_pattern,
        source_filter=source_filter,
        limit=limit,
        verbose=verbose
    )
    
    trace.log("ck3lens.search_content", {
        "query": query,
        "file_pattern": file_pattern,
        "verbose": verbose,
        "no_lens": no_lens
    }, {"count": len(results)})
    
    return {
        "query": query, 
        "count": len(results), 
        "results": results,
        "lens": lens.playset_name if lens else "ALL CONTENT (no lens)"
    }


# ============================================================================
# Conflicts Report Tools
# ============================================================================

@mcp.tool()
def ck3_generate_conflicts_report(
    domains_include: Optional[list[str]] = None,
    domains_exclude: Optional[list[str]] = None,
    paths_filter: Optional[str] = None,
    min_candidates: int = 2,
    min_risk_score: int = 0,
    output_format: Literal["summary", "json", "full"] = "summary"
) -> dict:
    """
    Generate a complete conflicts report for the active playset.
    
    This analyzes all file-level and ID-level conflicts and produces
    a deterministic, machine-readable report.
    
    Args:
        domains_include: Only analyze these domains (None = all)
        domains_exclude: Exclude these domains from analysis
        paths_filter: SQL LIKE pattern for paths (e.g., "common/on_action%")
        min_candidates: Minimum sources to count as conflict (default 2)
        min_risk_score: Only include conflicts with risk >= this score
        output_format: "summary" (CLI text), "json" (full JSON), "full" (both)
    
    Returns:
        Conflicts report in requested format
    """
    from ck3raven.resolver.report import ConflictsReportGenerator, report_summary_cli
    
    db = _get_db()
    trace = _get_trace()
    playset_id = _get_playset_id()
    
    generator = ConflictsReportGenerator(db.conn)
    report = generator.generate(
        playset_id=playset_id,
        domains_include=domains_include,
        domains_exclude=domains_exclude,
        paths_filter=paths_filter,
        min_candidates=min_candidates,
        min_risk_score=min_risk_score,
    )
    
    trace.log("ck3lens.generate_conflicts_report", {
        "domains_include": domains_include,
        "paths_filter": paths_filter,
    }, {
        "file_conflicts": report.summary.file_conflicts if report.summary else 0,
        "id_conflicts": report.summary.id_conflicts if report.summary else 0,
    })
    
    result = {}
    
    if output_format in ("summary", "full"):
        result["summary_text"] = report_summary_cli(report)
    
    if output_format in ("json", "full"):
        result["report"] = report.to_dict()
    
    # Always include key stats
    if report.summary:
        result["stats"] = {
            "file_conflicts": report.summary.file_conflicts,
            "id_conflicts": report.summary.id_conflicts,
            "high_risk": report.summary.high_risk_id_conflicts,
            "uncertain": report.summary.uncertain_conflicts,
        }
    
    return result


@mcp.tool()
def ck3_get_high_risk_conflicts(
    domain: Optional[str] = None,
    min_risk_score: int = 60,
    limit: int = 20
) -> dict:
    """
    Get the highest-risk conflicts for prioritized review.
    
    Args:
        domain: Filter by domain (on_action, events, etc.)
        min_risk_score: Minimum risk score (default 60 = high risk)
        limit: Maximum conflicts to return
    
    Returns:
        List of high-risk conflicts sorted by risk score
    """
    from ck3raven.resolver.report import ConflictsReportGenerator
    
    db = _get_db()
    trace = _get_trace()
    playset_id = _get_playset_id()
    
    generator = ConflictsReportGenerator(db.conn)
    report = generator.generate(
        playset_id=playset_id,
        domains_include=[domain] if domain else None,
        min_candidates=2,
        min_risk_score=0,  # We'll filter ourselves
    )
    
    # Combine and sort by risk
    all_conflicts = []
    
    for fc in report.file_level:
        if fc.risk and fc.risk.score >= min_risk_score:
            all_conflicts.append({
                "type": "file",
                "key": fc.vpath,
                "domain": fc.domain,
                "risk_score": fc.risk.score,
                "risk_bucket": fc.risk.bucket,
                "reasons": fc.risk.reasons,
                "candidate_count": len(fc.candidates),
                "winner": fc.winner_by_load_order.source_name if fc.winner_by_load_order else None,
            })
    
    for ic in report.id_level:
        if ic.risk and ic.risk.score >= min_risk_score:
            all_conflicts.append({
                "type": "id",
                "key": ic.unit_key,
                "domain": ic.domain,
                "container": ic.container_vpath,
                "risk_score": ic.risk.score,
                "risk_bucket": ic.risk.bucket,
                "reasons": ic.risk.reasons,
                "candidate_count": len(ic.candidates),
                "winner": ic.engine_effective_winner.candidate_id if ic.engine_effective_winner else None,
                "merge_semantics": ic.merge_semantics.expected if ic.merge_semantics else None,
            })
    
    # Sort by risk score descending
    all_conflicts.sort(key=lambda x: x["risk_score"], reverse=True)
    
    trace.log("ck3lens.get_high_risk_conflicts", {
        "domain": domain,
        "min_risk_score": min_risk_score,
    }, {"count": len(all_conflicts)})
    
    return {
        "count": len(all_conflicts),
        "conflicts": all_conflicts[:limit],
    }


# ============================================================================
# Log Parsing Tools
# ============================================================================

@mcp.tool()
def ck3_get_error_summary() -> dict:
    """
    Get summary of errors from the current CK3 error.log.
    
    Parses the error log and returns:
    - Total error count
    - Errors grouped by priority (1=critical to 5=low)
    - Errors grouped by category (script, encoding, missing reference, etc.)
    - Errors grouped by mod
    - Number of cascading error patterns detected
    
    Use this as the first step when diagnosing game issues.
    
    Returns:
        Summary statistics from error.log
    """
    from ck3raven.analyzers.error_parser import CK3ErrorParser
    
    parser = CK3ErrorParser()
    
    try:
        parser.parse_log()
        parser.detect_cascading_errors()
    except FileNotFoundError:
        return {
            "error": "error.log not found",
            "hint": "Make sure CK3 has been run at least once",
        }
    
    return parser.get_summary()


@mcp.tool()
def ck3_get_errors(
    priority: int | None = None,
    category: str | None = None,
    mod_filter: str | None = None,
    exclude_cascade_children: bool = True,
    limit: int = 50,
) -> dict:
    """
    Get filtered list of errors from the CK3 error.log.
    
    Args:
        priority: Max priority to include (1=critical, 2=high, 3=medium, 4=low, 5=very low)
        category: Filter by category (script_system_error, missing_reference, encoding_error, etc.)
        mod_filter: Filter by mod name (partial match)
        exclude_cascade_children: If True, exclude errors caused by cascade patterns
        limit: Maximum errors to return
    
    Returns:
        List of errors with details and fix hints
    """
    from ck3raven.analyzers.error_parser import CK3ErrorParser
    
    parser = CK3ErrorParser()
    
    try:
        parser.parse_log()
        parser.detect_cascading_errors()
    except FileNotFoundError:
        return {"error": "error.log not found"}
    
    errors = parser.get_errors(
        category=category,
        priority=priority,
        mod_filter=mod_filter,
        exclude_cascade_children=exclude_cascade_children,
        limit=limit,
    )
    
    # Convert to dicts with fix hints
    from ck3raven.analyzers.error_parser import ERROR_CATEGORIES
    
    results = []
    for error in errors:
        cat = next((c for c in ERROR_CATEGORIES if c.name == error.category), None)
        results.append({
            **error.to_dict(),
            "fix_hint": cat.fix_hint if cat else None,
        })
    
    return {
        "count": len(results),
        "total_in_log": parser.stats['total_errors'],
        "errors": results,
    }


@mcp.tool()
def ck3_search_errors(
    query: str,
    limit: int = 30,
) -> dict:
    """
    Search errors in the CK3 error.log by message or file path.
    
    Args:
        query: Search query (case-insensitive, matches message or file path)
        limit: Maximum results
    
    Returns:
        Matching errors
    """
    from ck3raven.analyzers.error_parser import CK3ErrorParser
    
    parser = CK3ErrorParser()
    
    try:
        parser.parse_log()
    except FileNotFoundError:
        return {"error": "error.log not found"}
    
    errors = parser.search_errors(query, limit=limit)
    
    return {
        "query": query,
        "count": len(errors),
        "errors": [e.to_dict() for e in errors],
    }


@mcp.tool()
def ck3_get_cascade_patterns() -> dict:
    """
    Get detected cascading error patterns from the error.log.
    
    Cascading errors are patterns where one root error causes many subsequent errors.
    Fixing the root error can eliminate many downstream errors.
    
    Pattern types:
    - script_parse_cascade: Script syntax error causing many "not defined" errors
    - mod_load_cascade: Encoding error causing mod-wide issues
    - repeated_error_spam: Same error repeated many times
    
    Returns:
        List of cascade patterns with root errors and child counts
    """
    from ck3raven.analyzers.error_parser import CK3ErrorParser
    
    parser = CK3ErrorParser()
    
    try:
        parser.parse_log()
        parser.detect_cascading_errors()
    except FileNotFoundError:
        return {"error": "error.log not found"}
    
    cascades = [c.to_dict() for c in parser.cascade_patterns]
    
    return {
        "cascade_count": len(cascades),
        "total_errors": parser.stats['total_errors'],
        "cascades": cascades,
        "recommendation": "Fix root errors first - they can eliminate many child errors",
    }


@mcp.tool()
def ck3_get_crash_reports(
    limit: int = 5,
) -> dict:
    """
    Get recent crash reports from CK3.
    
    Parses crash folders in the CK3 crashes directory, which contain:
    - exception.txt (stack trace)
    - meta.yml (crash metadata)
    - logs/ (copies of logs at crash time)
    
    Args:
        limit: Maximum number of crashes to return (default 5)
    
    Returns:
        List of crash reports with details
    """
    from ck3raven.analyzers.crash_parser import get_recent_crashes
    
    crashes = get_recent_crashes(limit=limit)
    
    if not crashes:
        return {
            "count": 0,
            "message": "No crash reports found",
        }
    
    return {
        "count": len(crashes),
        "crashes": [c.to_dict() for c in crashes],
    }


@mcp.tool()
def ck3_get_crash_detail(
    crash_id: str,
) -> dict:
    """
    Get detailed information about a specific crash.
    
    Args:
        crash_id: Crash folder name (e.g., "ck3_20251217_060926")
    
    Returns:
        Full crash report with logs and stack trace
    """
    from pathlib import Path
    from ck3raven.analyzers.crash_parser import parse_crash_folder
    
    crashes_dir = (
        Path.home() / "Documents" / "Paradox Interactive" / 
        "Crusader Kings III" / "crashes"
    )
    
    crash_path = crashes_dir / crash_id
    
    if not crash_path.exists():
        return {
            "error": f"Crash folder not found: {crash_id}",
            "hint": "Use ck3_get_crash_reports to see available crashes",
        }
    
    report = parse_crash_folder(crash_path)
    
    if not report:
        return {"error": "Failed to parse crash folder"}
    
    return report.to_dict()


@mcp.tool()
def ck3_read_log(
    log_type: str = "error",
    lines: int = 100,
    from_end: bool = True,
    search: str | None = None,
) -> dict:
    """
    Read content from a CK3 log file.
    
    Args:
        log_type: Type of log to read: "error", "game", "debug", "setup", "gui_warnings"
        lines: Number of lines to return (default 100)
        from_end: If True, return last N lines; otherwise first N lines
        search: Optional search filter (only return lines containing this text)
    
    Returns:
        Log content
    """
    from pathlib import Path
    
    logs_dir = (
        Path.home() / "Documents" / "Paradox Interactive" / 
        "Crusader Kings III" / "logs"
    )
    
    log_files = {
        "error": "error.log",
        "game": "game.log",
        "debug": "debug.log",
        "setup": "setup.log",
        "gui_warnings": "gui_warnings.log",
        "database_conflicts": "database_conflicts.log",
    }
    
    if log_type not in log_files:
        return {
            "error": f"Unknown log type: {log_type}",
            "available": list(log_files.keys()),
        }
    
    log_path = logs_dir / log_files[log_type]
    
    if not log_path.exists():
        return {
            "error": f"Log file not found: {log_files[log_type]}",
            "hint": "Make sure CK3 has been run",
        }
    
    try:
        content_lines = log_path.read_text(encoding='utf-8', errors='replace').splitlines()
        
        # Apply search filter if provided
        if search:
            search_lower = search.lower()
            content_lines = [l for l in content_lines if search_lower in l.lower()]
        
        # Select lines
        if from_end:
            selected = content_lines[-lines:] if len(content_lines) > lines else content_lines
        else:
            selected = content_lines[:lines]
        
        return {
            "log_type": log_type,
            "total_lines": len(content_lines),
            "returned_lines": len(selected),
            "from_end": from_end,
            "search": search,
            "content": "\n".join(selected),
        }
    except Exception as e:
        return {"error": str(e)}


# ============================================================================
# Explorer Tools (for UI navigation)
# ============================================================================

@mcp.tool()
def ck3_get_playset_mods() -> dict:
    """
    Get all mods in the active playset with load order.
    
    Returns list of mods with:
    - name: Display name
    - contentVersionId: For querying files
    - loadOrder: Position (0=vanilla, 1=first mod, etc.)
    - kind: 'vanilla' or 'mod'
    - fileCount: Number of files
    - sourcePath: Original source path (if known)
    """
    db = _get_db()
    playset_id = _get_playset_id()
    
    rows = db.conn.execute("""
        SELECT 
            pm.load_order_index,
            pm.content_version_id,
            cv.kind,
            cv.file_count,
            vv.ck3_version,
            mp.name as mod_name,
            mp.source_path
        FROM playset_mods pm
        JOIN content_versions cv ON pm.content_version_id = cv.content_version_id
        LEFT JOIN vanilla_versions vv ON cv.vanilla_version_id = vv.vanilla_version_id
        LEFT JOIN mod_packages mp ON cv.mod_package_id = mp.mod_package_id
        WHERE pm.playset_id = ? AND pm.enabled = 1
        ORDER BY pm.load_order_index
    """, (playset_id,)).fetchall()
    
    mods = []
    for row in rows:
        name = row['mod_name'] if row['mod_name'] else f"Vanilla CK3 {row['ck3_version'] or ''}"
        mods.append({
            "name": name,
            "contentVersionId": row['content_version_id'],
            "loadOrder": row['load_order_index'],
            "kind": row['kind'],
            "fileCount": row['file_count'],
            "sourcePath": row['source_path']
        })
    
    return {"mods": mods, "playset_id": playset_id}


@mcp.tool()
def ck3_get_top_level_folders() -> dict:
    """
    Get top-level folders across all mods in the active playset.
    
    Returns unique folder names with file counts.
    """
    db = _get_db()
    playset_id = _get_playset_id()
    
    rows = db.conn.execute("""
        SELECT 
            SUBSTR(f.relpath, 1, INSTR(f.relpath || '/', '/') - 1) as folder,
            COUNT(*) as file_count
        FROM files f
        JOIN playset_mods pm ON f.content_version_id = pm.content_version_id
        WHERE pm.playset_id = ? AND pm.enabled = 1 AND f.deleted = 0
        GROUP BY folder
        ORDER BY folder
    """, (playset_id,)).fetchall()
    
    folders = [{"name": row['folder'], "fileCount": row['file_count']} for row in rows if row['folder']]
    return {"folders": folders}


@mcp.tool()
def ck3_get_mod_folders(content_version_id: int) -> dict:
    """
    Get top-level folders within a specific mod.
    
    Args:
        content_version_id: The content version to query
    
    Returns folders with file counts.
    """
    db = _get_db()
    
    rows = db.conn.execute("""
        SELECT 
            SUBSTR(f.relpath, 1, INSTR(f.relpath || '/', '/') - 1) as folder,
            COUNT(*) as file_count
        FROM files f
        WHERE f.content_version_id = ? AND f.deleted = 0
        GROUP BY folder
        ORDER BY folder
    """, (content_version_id,)).fetchall()
    
    folders = [{"name": row['folder'], "fileCount": row['file_count']} for row in rows if row['folder']]
    return {"folders": folders}


@mcp.tool()
def ck3_get_folder_contents(
    path: str,
    content_version_id: Optional[int] = None,
    folder_pattern: Optional[str] = None,
    text_search: Optional[str] = None,
    symbol_search: Optional[str] = None,
    mod_filter: Optional[list[str]] = None,
    file_type_filter: Optional[list[str]] = None
) -> dict:
    """
    Get contents of a folder - subfolders and files.
    
    Args:
        path: Folder path (e.g., "common/traits")
        content_version_id: Limit to specific mod (optional)
        folder_pattern: Filter by folder pattern
        text_search: Filter by content text (FTS)
        symbol_search: Filter by symbol name
        mod_filter: Only show files from these mods
        file_type_filter: Only show these file types
    
    Returns subfolders and files in the path.
    """
    db = _get_db()
    playset_id = _get_playset_id()
    
    # Normalize path
    path = path.strip('/').replace('\\', '/')
    path_prefix = f"{path}/" if path else ""
    
    # Build query for subfolders
    if content_version_id:
        # Single mod query
        subfolder_sql = """
            SELECT DISTINCT
                SUBSTR(f.relpath, ?, INSTR(SUBSTR(f.relpath, ?), '/')) as subfolder
            FROM files f
            WHERE f.content_version_id = ? 
              AND f.relpath LIKE ?
              AND f.deleted = 0
              AND SUBSTR(f.relpath, ?, INSTR(SUBSTR(f.relpath, ?), '/')) != ''
        """
        prefix_len = len(path_prefix) + 1
        subfolder_rows = db.conn.execute(subfolder_sql, (
            prefix_len, prefix_len, content_version_id, f"{path_prefix}%", prefix_len, prefix_len
        )).fetchall()
    else:
        # All mods in playset
        subfolder_sql = """
            SELECT DISTINCT
                SUBSTR(f.relpath, ?, INSTR(SUBSTR(f.relpath, ?), '/')) as subfolder
            FROM files f
            JOIN playset_mods pm ON f.content_version_id = pm.content_version_id
            WHERE pm.playset_id = ? 
              AND pm.enabled = 1
              AND f.relpath LIKE ?
              AND f.deleted = 0
              AND SUBSTR(f.relpath, ?, INSTR(SUBSTR(f.relpath, ?), '/')) != ''
        """
        prefix_len = len(path_prefix) + 1
        subfolder_rows = db.conn.execute(subfolder_sql, (
            prefix_len, prefix_len, playset_id, f"{path_prefix}%", prefix_len, prefix_len
        )).fetchall()
    
    # Count files in each subfolder
    subfolders = []
    seen_folders = set()
    for row in subfolder_rows:
        if row['subfolder'] and row['subfolder'] not in seen_folders:
            seen_folders.add(row['subfolder'])
            subfolders.append({"name": row['subfolder']})
    
    # Build query for files in this exact folder (not subfolders)
    if content_version_id:
        file_sql = """
            SELECT 
                f.file_id,
                f.relpath,
                f.content_hash,
                f.file_type,
                cv.kind,
                mp.name as mod_name,
                mp.source_path
            FROM files f
            JOIN content_versions cv ON f.content_version_id = cv.content_version_id
            LEFT JOIN mod_packages mp ON cv.mod_package_id = mp.mod_package_id
            WHERE f.content_version_id = ?
              AND f.relpath LIKE ?
              AND f.relpath NOT LIKE ?
              AND f.deleted = 0
            ORDER BY f.relpath
        """
        file_rows = db.conn.execute(file_sql, (
            content_version_id, f"{path_prefix}%", f"{path_prefix}%/%"
        )).fetchall()
    else:
        file_sql = """
            SELECT 
                f.file_id,
                f.relpath,
                f.content_hash,
                f.file_type,
                cv.kind,
                mp.name as mod_name,
                mp.source_path,
                pm.load_order_index
            FROM files f
            JOIN playset_mods pm ON f.content_version_id = pm.content_version_id
            JOIN content_versions cv ON f.content_version_id = cv.content_version_id
            LEFT JOIN mod_packages mp ON cv.mod_package_id = mp.mod_package_id
            WHERE pm.playset_id = ?
              AND pm.enabled = 1
              AND f.relpath LIKE ?
              AND f.relpath NOT LIKE ?
              AND f.deleted = 0
            ORDER BY pm.load_order_index, f.relpath
        """
        file_rows = db.conn.execute(file_sql, (
            playset_id, f"{path_prefix}%", f"{path_prefix}%/%"
        )).fetchall()
    
    # Build file list with absolute paths
    files = []
    for row in file_rows:
        mod_name = row['mod_name'] if row['mod_name'] else f"Vanilla"
        
        # Determine absolute path
        abs_path = None
        if row['source_path']:
            abs_path = str(Path(row['source_path']) / row['relpath'])
        
        files.append({
            "relpath": row['relpath'],
            "modName": mod_name,
            "contentHash": row['content_hash'],
            "fileType": row['file_type'] or 'text',
            "absPath": abs_path
        })
    
    return {
        "folders": subfolders,
        "files": files,
        "path": path
    }


# ============================================================================
# Mode & Configuration Tools
# ============================================================================

@mcp.tool()
def ck3_get_mode_instructions(
    mode: Literal["ck3lens", "ck3lens-live", "ck3raven-dev"]
) -> dict:
    """
    Get the instruction content for a specific agent mode.
    
    Use this to understand what a mode does or to switch modes.
    
    Args:
        mode: The mode to get instructions for:
            - "ck3lens": Database-only CK3 modding (restricted tools)
            - "ck3lens-live": Full CK3 modding with live file editing
            - "ck3raven-dev": Full development mode for infrastructure
    
    Returns:
        Mode instructions and configuration
    """
    from pathlib import Path
    
    # Map modes to instruction files
    mode_files = {
        "ck3lens": "COPILOT_LENS_COMPATCH.md",
        "ck3lens-live": "COPILOT_LENS_COMPATCH.md",  # Same file, different tool access
        "ck3raven-dev": "COPILOT_RAVEN_DEV.md",
    }
    
    if mode not in mode_files:
        return {
            "error": f"Unknown mode: {mode}",
            "available_modes": list(mode_files.keys()),
        }
    
    # Find the instructions file
    ck3raven_root = Path(__file__).parent.parent.parent
    instructions_path = ck3raven_root / ".github" / mode_files[mode]
    
    if not instructions_path.exists():
        return {
            "error": f"Instructions file not found: {mode_files[mode]}",
            "expected_path": str(instructions_path),
        }
    
    try:
        content = instructions_path.read_text(encoding="utf-8")
        
        # Add mode-specific notes
        mode_notes = {
            "ck3lens": "Restricted mode: Use only MCP tools, no filesystem access.",
            "ck3lens-live": "Full CK3 modding: All MCP tools including live file operations.",
            "ck3raven-dev": "Development mode: All tools available for infrastructure work.",
        }
        
        return {
            "mode": mode,
            "note": mode_notes.get(mode, ""),
            "instructions": content,
            "source_file": str(instructions_path),
        }
    except Exception as e:
        return {"error": str(e)}


@mcp.tool()
def ck3_get_workspace_config() -> dict:
    """
    Get the workspace configuration including tool sets and MCP settings.
    
    Use this to understand:
    - Available modes/tool sets and what tools they enable
    - MCP server configuration
    - Live mod whitelist
    - Database path
    
    Returns:
        Complete workspace configuration
    """
    from pathlib import Path
    import json
    
    session = _get_session()
    
    result = {
        "database": {
            "path": str(session.db_path),
            "exists": session.db_path.exists(),
        },
        "live_mods": [
            {"mod_id": m.mod_id, "name": m.name, "path": str(m.path)}
            for m in (session.live_mods or [])
        ],
        "tool_sets": None,
        "mcp_config": None,
        "available_modes": [
            {
                "name": "ck3lens",
                "description": "Database-only CK3 modding - searches, symbols, file content, conflict detection",
                "use_case": "Fixing mod errors, compatibility patching",
            },
            {
                "name": "ck3lens-live",
                "description": "Full CK3 modding including live file editing and git operations",
                "use_case": "Active mod development with file writes",
            },
            {
                "name": "ck3raven-dev",
                "description": "Full development mode - all tools for infrastructure work",
                "use_case": "Python development, MCP server changes, database schema",
            },
        ],
    }
    
    # Try to read toolSets.json
    ai_workspace = Path(__file__).parent.parent.parent.parent
    tool_sets_path = ai_workspace / ".vscode" / "toolSets.json"
    
    if tool_sets_path.exists():
        try:
            result["tool_sets"] = json.loads(tool_sets_path.read_text(encoding="utf-8"))
            result["tool_sets_path"] = str(tool_sets_path)
        except Exception as e:
            result["tool_sets_error"] = str(e)
    
    # Try to read mcp.json
    mcp_paths = [
        ai_workspace / ".vscode" / "mcp.json",
        ai_workspace / "ck3raven" / ".vscode" / "mcp.json",
    ]
    
    for mcp_path in mcp_paths:
        if mcp_path.exists():
            try:
                # Read as text and strip comments for JSONC
                content = mcp_path.read_text(encoding="utf-8")
                # Simple JSONC handling: remove // comments
                lines = [l for l in content.splitlines() if not l.strip().startswith("//")]
                clean_json = "\n".join(lines)
                result["mcp_config"] = json.loads(clean_json)
                result["mcp_config_path"] = str(mcp_path)
                break
            except Exception as e:
                result["mcp_config_error"] = str(e)
    
    return result


# ============================================================================
# Main Entry Point
# ============================================================================

if __name__ == "__main__":
    mcp.run()

